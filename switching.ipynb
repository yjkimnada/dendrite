{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switching(nn.Module):\n",
    "    def __init__(self, sub_no, state_no, hid_no, C_syn, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N_no = sub_no\n",
    "        self.K_no = state_no\n",
    "        self.H_no = hid_no\n",
    "        self.device = device\n",
    "        self.C_syn = C_syn\n",
    "        self.in_no = C_syn.shape[1]\n",
    "        \n",
    "        self.encoder = nn.GRU(self.N_no, 10, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.encoder_lin = nn.Linear(20, self.N_no*self.K_no)\n",
    "        self.spike = nn.Parameter(torch.ones(self.in_no), requires_grad=True)\n",
    "        \n",
    "        self.W_sz = nn.Parameter(torch.randn(self.N_no, self.K_no, self.K_no, self.H_no)*0.1, requires_grad=True)\n",
    "        self.W_sx = nn.Parameter(torch.randn(self.N_no, self.K_no, self.K_no)*0.1, requires_grad=True)\n",
    "        self.b_s = nn.Parameter(torch.randn(self.N_no, self.K_no, self.K_no)*0.1, requires_grad=True)\n",
    "        \n",
    "        self.W_zz = nn.Parameter(torch.randn(self.N_no, self.K_no, self.H_no, self.H_no)*0.1, requires_grad=True)\n",
    "        self.W_zx = nn.Parameter(torch.randn(self.N_no, self.K_no, self.H_no)*0.1, requires_grad=True)\n",
    "        self.b_z = nn.Parameter(torch.randn(self.N_no, self.K_no, self.H_no)*0.1, requires_grad=True)\n",
    "        \n",
    "        self.W_yz = nn.Parameter(torch.randn(self.N_no * self.H_no)*0.1, requires_grad=True)\n",
    "        self.b_y = nn.Parameter(torch.randn(1)*0.1, requires_grad=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train_forward(self, X, temp):\n",
    "        # X is (batch_size, T_data, E_no)\n",
    "        T_data = X.shape[1]\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        X_scaled = X * self.spike.reshape(1,1,-1)\n",
    "        X_sub = torch.matmul(X_scaled, self.C_syn.T) # (batch, T_data, N_no)\n",
    "        \n",
    "        encoder_out, _ = self.encoder(X_sub)\n",
    "        S_encode_raw = self.encoder_lin(encoder_out.reshape(batch_size, T_data, -1)) # (batch, T_data, K_no*N_no)\n",
    "        S_encode = F.softmax(S_encode_raw.reshape(batch_size, T_data, self.N_no, self.K_no) / temp, 3) # (batch, T_data, N_no, K_no)\n",
    "        S_encode_pad = torch.zeros(batch_size, T_data+1, self.N_no, self.K_no).to(self.device)\n",
    "        S_encode_pad[:,-T_data:,:,:] = S_encode_pad[:,-T_data:,:,:] + S_encode\n",
    "        S_encode_pad[:,:,:,0] = 1\n",
    "        \n",
    "        Z_decode = torch.zeros(batch_size, T_data+1, self.N_no, self.H_no).to(self.device)\n",
    "        S_decode = torch.zeros(batch_size, T_data+1, self.N_no, self.K_no).to(self.device)\n",
    "        S_decode[:,:,:,0] = 1\n",
    "        \n",
    "        for t in range(T_data):\n",
    "            for n in range(self.N_no):\n",
    "                prev_S = S_encode_pad[:,t,n,:].clone() # (batch, K_no)\n",
    "                prev_Z = Z_decode[:,t,n].clone()\n",
    "                curr_X = X_sub[:,t,n]\n",
    "                curr_S = S_encode_pad[:,t+1,n,:].clone()\n",
    "                \n",
    "                ### Calculate state vector ###\n",
    "                \n",
    "                W_sz_part = torch.sum(prev_S.unsqueeze(2).unsqueeze(3) * self.W_sz[n], 1) # (batch, K_no, H_no)\n",
    "                W_sx_part = torch.sum(prev_S.unsqueeze(2) * self.W_sx[n], 1) # (batch, K_no)\n",
    "                b_s_part = torch.sum(prev_S.unsqueeze(2) * self.b_s[n], 1) # (batch, K_no)\n",
    "                \n",
    "                S_in = torch.matmul(W_sz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                                + W_sx_part * curr_X.unsqueeze(1) \\\n",
    "                                + b_s_part # (batch, K_no)\n",
    "                \n",
    "                curr_S_est = torch.zeros(batch_size, self.K_no).to(self.device)\n",
    "                for b in range(batch_size):\n",
    "                    max_idx = torch.argmax(S_in[b])\n",
    "                    curr_S_est[b,max_idx] = 1\n",
    "                    \n",
    "                S_decode[:,t+1,n,:] = S_decode[:,t+1,n,:] + curr_S_est # (batch, K_no)\n",
    "                \n",
    "                ### Calculate hidden Z ###\n",
    "                \n",
    "                W_zz_part = torch.sum(curr_S.unsqueeze(2).unsqueeze(3) * self.W_zz[n], 1) # (batch, H_no, H_no)\n",
    "                W_zx_part = torch.sum(curr_S.unsqueeze(2) * self.W_zx[n], 1) # (batch, H_no)\n",
    "                b_z_part = torch.sum(curr_S.unsqueeze(2) * self.b_z[n], 1) # (batch, H_no)\n",
    "                \n",
    "                Z_in = torch.matmul(W_zz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                            + W_zx_part * curr_X.unsqueeze(1) \\\n",
    "                            + b_z_part # (batch, H_no)\n",
    "                curr_Z = torch.tanh(Z_in) # (batch, H_no)\n",
    "                Z_decode[:,t+1,n,:] = Z_decode[:,t+1,n,:] + curr_Z\n",
    "                \n",
    "        Y_out = torch.sum(Z_decode[:,1:,:,:].reshape(batch_size, T_data, -1) * self.W_yz.reshape(1,1,-1), 2) + self.b_y\n",
    "        \n",
    "        return Y_out, Z_decode[:,1:,:,:], S_decode[:,1:,:,:], S_encode\n",
    "        \n",
    "    def test_forward(self, X):\n",
    "        # X is (batch_size, T_data, E_no)\n",
    "        T_data = X.shape[1]\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        X_scaled = X * self.spike.reshape(1,1,-1)\n",
    "        X_sub = torch.matmul(X_scaled, self.C_syn.T) # (batch, T_data, N_no)\n",
    "        \n",
    "        Z_decode = torch.zeros(batch_size, T_data+1, self.N_no, self.H_no).to(self.device)\n",
    "        S_decode = torch.zeros(batch_size, T_data+1, self.N_no, self.K_no).to(self.device)\n",
    "        S_decode[:,:,:,0] = 1\n",
    "        \n",
    "        for t in range(T_data):\n",
    "            for n in range(self.N_no):\n",
    "                prev_S = S_decode[:,t,n,:].clone() # (batch, K_no)\n",
    "                prev_Z = Z_decode[:,t,n].clone()\n",
    "                curr_X = X_sub[:,t,n]\n",
    "                \n",
    "                ### Calculate state vector ###\n",
    "                \n",
    "                W_sz_part = torch.sum(prev_S.unsqueeze(2).unsqueeze(3) * self.W_sz[n], 1) # (batch, K_no, H_no)\n",
    "                W_sx_part = torch.sum(prev_S.unsqueeze(2) * self.W_sx[n], 1) # (batch, K_no)\n",
    "                b_s_part = torch.sum(prev_S.unsqueeze(2) * self.b_s[n], 1) # (batch, K_no)\n",
    "                \n",
    "                S_in = torch.matmul(W_sz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                                + W_sx_part * curr_X.unsqueeze(1) \\\n",
    "                                + b_s_part # (batch, K_no)\n",
    "                \n",
    "                curr_S = torch.zeros(batch_size, self.K_no).to(self.device)\n",
    "                for b in range(batch_size):\n",
    "                    max_idx = torch.argmax(S_in[b])\n",
    "                    curr_S[b,max_idx] = 1\n",
    "                    \n",
    "                S_decode[:,t+1,n,:] = S_decode[:,t+1,n,:] + curr_S # (batch, K_no)\n",
    "                \n",
    "                ### Calculate hidden Z ###\n",
    "                \n",
    "                W_zz_part = torch.sum(curr_S.unsqueeze(2).unsqueeze(3) * self.W_zz[n], 1) # (batch, H_no, H_no)\n",
    "                W_zx_part = torch.sum(curr_S.unsqueeze(2) * self.W_zx[n], 1) # (batch, H_no)\n",
    "                b_z_part = torch.sum(curr_S.unsqueeze(2) * self.b_z[n], 1) # (batch, H_no)\n",
    "                \n",
    "                Z_in = torch.matmul(W_zz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                            + W_zx_part * curr_X.unsqueeze(1) \\\n",
    "                            + b_z_part # (batch, H_no)\n",
    "                curr_Z = torch.tanh(Z_in) # (batch, H_no)\n",
    "                Z_decode[:,t+1,n,:] = Z_decode[:,t+1,n,:] + curr_Z\n",
    "                \n",
    "        Y_out = torch.sum(Z_decode[:,1:,:,:].reshape(batch_size, T_data, -1) * self.W_yz.reshape(1,1,-1), 2) + self.b_y\n",
    "        \n",
    "        return Y_out, Z_decode[:,1:,:,:], S_decode[:,1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/hdd01/sklee/\"\n",
    "experiment = \"clust4-60\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "V_file = \"V_diff.npy\"\n",
    "eloc_file = \"Elocs_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1.npy\"\n",
    "\n",
    "E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "V = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+V_file)\n",
    "V = torch.from_numpy(V)\n",
    "eloc = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+eloc_file)\n",
    "\n",
    "den_idx = np.unique(eloc[880:1120,0])\n",
    "e_idx = np.where(np.isin(eloc[:,0], den_idx) == True)[0]\n",
    "e_idx = torch.from_numpy(e_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = 999 * 1000 * 50\n",
    "T_test = 1 * 1000 * 50\n",
    "hid_no = 2 # H\n",
    "sub_no = 4 # N\n",
    "state_no = 3 # K\n",
    "in_no = 299\n",
    "save_dir = base_dir+cell_type+\"_\"+experiment+\"/\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_length = 50000\n",
    "batch_size = 9\n",
    "iter_no = 20000\n",
    "epoch_no = iter_no*batch_length*batch_size//T_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train = V[:T_train].float()\n",
    "V_test = V[T_train:T_train + T_test].to(device).float()\n",
    "\n",
    "test_E_neural = E_neural[T_train:T_train+T_test].toarray()\n",
    "train_E_neural = E_neural[:T_train]\n",
    "test_E_neural = torch.from_numpy(test_E_neural).float().to(device)\n",
    "\n",
    "train_idx = np.empty((epoch_no, T_train//batch_length//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0, T_train, batch_length*batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_syn = torch.zeros(sub_no, in_no).to(device)\n",
    "for i in range(in_no):\n",
    "    idx = e_idx[i]\n",
    "    if eloc[idx,0] == den_idx[0]:\n",
    "        C_syn[0,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[1]:\n",
    "        C_syn[1,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[2]:\n",
    "        C_syn[2,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[3]:\n",
    "        C_syn[3,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760\n"
     ]
    }
   ],
   "source": [
    "model = Switching(sub_no, state_no, hid_no, C_syn, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.75)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "bce_criterion = nn.BCELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0736c4137f88>:4: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae260008e844d89b464ba6e3b4bdd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "249.29005217552185\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "the derivative for 'target' is not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0736c4137f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mV_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mS_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m     return torch._C._nn.binary_cross_entropy(\n\u001b[0m\u001b[1;32m   2526\u001b[0m         input, target, weight, reduction_enum)\n\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the derivative for 'target' is not implemented"
     ]
    }
   ],
   "source": [
    "temp_list = np.logspace(-0.5, -3, 50)\n",
    "temp_count = 0\n",
    "\n",
    "for i in tnrange(iter_no):\n",
    "    s = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (i%50 == 49) & (temp_count < 49):\n",
    "        temp_count += 1\n",
    "    temp = temp_list[temp_count] \n",
    "    \n",
    "    batch_idx = train_idx[i].long()\n",
    "    batch_E_neural = train_E_neural[batch_idx : batch_idx+batch_length*batch_size].toarray().reshape(batch_size, batch_length, -1)\n",
    "    batch_E_neural = torch.from_numpy(batch_E_neural).float().to(device)\n",
    "    batch_V = V_train[batch_idx : batch_idx+batch_length*batch_size].reshape(batch_size, -1).to(device)\n",
    "    \n",
    "    V_pred, Z_dec, S_dec, S_enc = model.train_forward(batch_E_neural[:,:,e_idx], temp)\n",
    "    \n",
    "    print(\"forward\")\n",
    "    print(time.time()-s)\n",
    "    s = time.time()\n",
    "                \n",
    "    V_loss = torch.mean((V_pred - batch_V)**2)\n",
    "    S_loss = bce_criterion(S_dec, S_enc)\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    \n",
    "    print(\"backward\")\n",
    "    print(time.time() - s)\n",
    "    \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_V_pred, test_Z_dec, test_S_dec = model.test_forward(test_E_neural[:,e_idx].unsqueeze(0))        \n",
    "        test_V_pred = test_V_pred.flatten()\n",
    "                 \n",
    "        test_score = explained_variance_score(V_test.cpu().detach().numpy(), test_V_pred.cpu().detach().numpy())\n",
    "        test_mse = torch.mean((V_test-test_V_pred)**2).item()\n",
    "        \n",
    "        print(i, np.round(test_score,6),\n",
    "              np.round(test_mse,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
