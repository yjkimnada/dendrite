{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from models.sub_cos_glm import Sub_Cos_GLM\n",
    "#from models.sub_tcn import Sub_TCN\n",
    "from models.gru import GRU\n",
    "from models.gru_stacked import GRU_Stacked\n",
    "from models.sub_cos_glm_stacked import Sub_Cos_GLM_Stacked\n",
    "from models.gru_multilayer import GRU_Multilayer\n",
    "from models.sub_cos_glm_multilayer import Sub_Cos_GLM_Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/hdd01/sklee/\"\n",
    "experiment = \"clust12-20_noNA\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "I_neural_file = \"Ispikes_neural.npz\"\n",
    "clust_mode = \"hand\"\n",
    "model_type = \"glm\"\n",
    "\n",
    "E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "I_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+I_neural_file)\n",
    "\n",
    "if (clust_mode == \"hand\") or (clust_mode == \"whole\") or (clust_mode == \"global\"):\n",
    "    C_syn_e = np.load(\"/media/hdd01/sklee/\"+cell_type+\"_\"+experiment+\"/data/handsub18_C_syn_e.npy\")\n",
    "    C_syn_i = np.load(\"/media/hdd01/sklee/\"+cell_type+\"_\"+experiment+\"/data/handsub18_C_syn_i.npy\")\n",
    "    C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "    C_syn_i = torch.from_numpy(C_syn_i).float()\n",
    "elif clust_mode == \"rand\":\n",
    "    C_syn_e = np.load(\"/media/hdd01/sklee/\"+cell_type+\"_\"+experiment+\"/data/randsub5_C_syn_e.npy\")\n",
    "    C_syn_i = np.load(\"/media/hdd01/sklee/\"+cell_type+\"_\"+experiment+\"/data/randsub5_C_syn_i.npy\")\n",
    "    C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "    C_syn_i = torch.from_numpy(C_syn_i).float()\n",
    "\n",
    "#C_syn_e = np.load(\"/media/hdd01/sklee/CA1_clust8-30/data/handsub1_C_syn_e.npy\")\n",
    "#C_syn_i = np.load(\"/media/hdd01/sklee/CA1_clust8-30/data/handsub1_C_syn_i.npy\")\n",
    "#C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "#C_syn_i = torch.from_numpy(C_syn_i).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_no = 2\n",
    "sub_no = 18\n",
    "E_no = 2000\n",
    "I_no = 200\n",
    "T_no = 500\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4433\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"gru\":\n",
    "    model = GRU(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "elif model_type == \"grustack\":\n",
    "    model = GRU_Stacked(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "elif model_type == \"glm\":\n",
    "    model = Sub_Cos_GLM(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"glmstack\":\n",
    "    model = Sub_Cos_GLM_Stacked(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"grumulti\":\n",
    "    model = GRU_Multilayer(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "elif model_type == \"glmmulti\":\n",
    "    model = Sub_Cos_GLM_Multilayer(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "    \n",
    "model.to(device).float()\n",
    "model.load_state_dict(torch.load(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no)+\"_h\"+str(H_no)+\".pt\", map_location='cpu'))\n",
    "#model.load_state_dict(torch.load(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no_file)+\"_h\"+str(H_no)+\"_set5.pt\", map_location='cuda:0'))\n",
    "model.eval()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17894/4052821804.py:4: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(1000//batch_size):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d1da1445514762a64dd1941c00fddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = np.zeros((1000,50000))\n",
    "batch_size = 5\n",
    "\n",
    "for i in tnrange(1000//batch_size):\n",
    "    part_E_neural = torch.from_numpy(E_neural[i*batch_size*50000:(i+1)*batch_size*50000].toarray().reshape(batch_size,50000,-1)).to(device).float()\n",
    "    part_I_neural = torch.from_numpy(I_neural[i*batch_size*50000:(i+1)*batch_size*50000].toarray().reshape(batch_size,50000,-1)).to(device).float()\n",
    "    #part_test, _ = model(part_E_neural, part_I_neural)\n",
    "    part_test, _, _ = model(part_E_neural, part_I_neural)\n",
    "    test[i*batch_size:(i+1)*batch_size] = part_test.cpu().detach().numpy().reshape(batch_size,50000)\n",
    "        \n",
    "np.save(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no)+\"_h\"+str(H_no)+\"_Vall.npy\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
