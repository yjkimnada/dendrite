{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17b9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "import matplotlib as mpl\n",
    "from weightedcorr import WeightedCorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170327e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29970/2090799982.py:24: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(rep_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca23d5c81524ab0af3bdca149bb0f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rep_no = 5\n",
    "\n",
    "C4_diff_all = np.zeros((rep_no, 2000,2000))\n",
    "C4_nona_all = np.zeros((rep_no, 2000,2000))\n",
    "C8_diff_all = np.zeros((rep_no, 2000,2000))\n",
    "C8_nona_all = np.zeros((rep_no, 2000,2000))\n",
    "C12_diff_all = np.zeros((rep_no, 2000,2000))\n",
    "C12_nona_all = np.zeros((rep_no, 2000,2000))\n",
    "\n",
    "C4_diff_scale_all = np.zeros((rep_no, 2000))\n",
    "C4_nona_scale_all = np.zeros((rep_no, 2000))\n",
    "C8_diff_scale_all = np.zeros((rep_no, 2000))\n",
    "C8_nona_scale_all = np.zeros((rep_no, 2000))\n",
    "C12_diff_scale_all = np.zeros((rep_no, 2000))\n",
    "C12_nona_scale_all = np.zeros((rep_no, 2000))\n",
    "\n",
    "C4_rand_all = np.zeros((rep_no, 2000, 2000))\n",
    "C4_rand_scale_all = np.random.rand(rep_no, 2000)\n",
    "C8_rand_all = np.zeros((rep_no, 2000, 2000))\n",
    "C8_rand_scale_all = np.random.rand(rep_no, 2000)\n",
    "C12_rand_all = np.zeros((rep_no, 2000, 2000))\n",
    "C12_rand_scale_all = np.random.rand(rep_no, 2000)\n",
    "\n",
    "for i in tnrange(rep_no):\n",
    "    if i == 0:\n",
    "        C4_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C4_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C8_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C8_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30_noNA/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C12_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C12_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20_noNA/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "\n",
    "        C4_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60/data/clust4_syn_dist.npy\")[:,-1]\n",
    "        C8_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30/data/clust8_syn_dist.npy\")[:,-1]\n",
    "        C12_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20/data/clust12_syn_dist.npy\")[:,-1]\n",
    "\n",
    "        C4_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust4-60/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C4_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C8_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust8-30/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C8_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust8-30_noNA/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C12_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust12-20/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C12_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust12-20_noNA/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "    \n",
    "    else:\n",
    "        C4_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C4_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C8_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C8_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30_noNA/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C12_diff_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "        C12_nona_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20_noNA/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"C_syn_e\"]\n",
    "\n",
    "        C4_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust4-60/data/clust4_syn_dist.npy\")[:,-1]\n",
    "        C8_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust8-30/data/clust8_syn_dist.npy\")[:,-1]\n",
    "        C12_dist_raw = np.load(\"/media/hdd01/sklee/CA1_clust12-20/data/clust12_syn_dist.npy\")[:,-1]\n",
    "\n",
    "        C4_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust4-60/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C4_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/clust/gru_s5_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C8_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust8-30/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C8_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust8-30_noNA/clust/gru_s9_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C12_diff_scale = np.load(\"/media/hdd01/sklee/CA1_clust12-20/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "        C12_nona_scale = np.load(\"/media/hdd01/sklee/CA1_clust12-20_noNA/clust/gru_s13_h20_pretrain_output_set\"+str(i+1)+\".npz\")[\"E_scale\"]\n",
    "    \n",
    "    C4_diff_scale_all[i] = C4_diff_scale\n",
    "    C4_nona_scale_all[i] = C4_nona_scale\n",
    "    C8_diff_scale_all[i] = C8_diff_scale\n",
    "    C8_nona_scale_all[i] = C8_nona_scale\n",
    "    C12_diff_scale_all[i] = C12_diff_scale\n",
    "    C12_nona_scale_all[i] = C12_nona_scale\n",
    "    \n",
    "    C4_diff_idx = np.zeros((2000))\n",
    "    C4_nona_idx = np.zeros((2000))\n",
    "    C8_diff_idx = np.zeros((2000))\n",
    "    C8_nona_idx = np.zeros((2000))\n",
    "    C12_diff_idx = np.zeros((2000))\n",
    "    C12_nona_idx = np.zeros((2000))\n",
    "    \n",
    "    C4_rand_idx = np.random.randint(0,5,(2000))\n",
    "    C8_rand_idx = np.random.randint(0,8,(2000))\n",
    "    C12_rand_idx = np.random.randint(0,12,(2000))\n",
    "\n",
    "    for j in range(2000):\n",
    "        C4_diff_idx[j] = np.argmax(C4_diff_raw[:,j])\n",
    "        C4_nona_idx[j] = np.argmax(C4_nona_raw[:,j])\n",
    "        C8_diff_idx[j] = np.argmax(C8_diff_raw[:,j])\n",
    "        C8_nona_idx[j] = np.argmax(C8_nona_raw[:,j])\n",
    "        C12_diff_idx[j] = np.argmax(C12_diff_raw[:,j])\n",
    "        C12_nona_idx[j] = np.argmax(C12_nona_raw[:,j])\n",
    "\n",
    "    for j in range(2000):\n",
    "        for k in range(2000):\n",
    "            if C4_diff_idx[j] != C4_diff_idx[k]:\n",
    "                C4_diff_all[i,j,k] = 1\n",
    "                C4_diff_all[i,k,j] = 1\n",
    "            if C4_nona_idx[j] != C4_nona_idx[k]:\n",
    "                C4_nona_all[i,j,k] = 1\n",
    "                C4_nona_all[i,k,j] = 1\n",
    "            if C8_diff_idx[j] != C8_diff_idx[k]:\n",
    "                C8_diff_all[i,j,k] = 1\n",
    "                C8_diff_all[i,k,j] = 1\n",
    "            if C8_nona_idx[j] != C8_nona_idx[k]:\n",
    "                C8_nona_all[i,j,k] = 1\n",
    "                C8_nona_all[i,k,j] = 1\n",
    "            if C12_diff_idx[j] != C12_diff_idx[k]:\n",
    "                C12_diff_all[i,j,k] = 1\n",
    "                C12_diff_all[i,k,j] = 1\n",
    "            if C12_nona_idx[j] != C12_nona_idx[k]:\n",
    "                C12_nona_all[i,j,k] = 1\n",
    "                C12_nona_all[i,k,j] = 1\n",
    "            if C4_rand_idx[j] != C4_rand_idx[k]:\n",
    "                C4_rand_all[i,j,k] = 1\n",
    "                C4_rand_all[i,k,j] = 1\n",
    "            if C8_rand_idx[j] != C8_rand_idx[k]:\n",
    "                C8_rand_all[i,j,k] = 1\n",
    "                C8_rand_all[i,k,j] = 1\n",
    "            if C12_rand_idx[j] != C12_rand_idx[k]:\n",
    "                C12_rand_all[i,j,k] = 1\n",
    "                C12_rand_all[i,k,j] = 1\n",
    "\n",
    "gru4_diff_subout = np.load(\"/media/hdd01/sklee/CA1_clust4-60/clust/gru_s5_h20_pretrain_output_set1.npz\")[\"sub_out\"][-1,:]\n",
    "gru4_nona_subout = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/clust/gru_s5_h20_pretrain_output_set1.npz\")[\"sub_out\"][-1,:]\n",
    "true4_dend_na = np.load(\"/media/hdd01/sklee/CA1_clust4-60/data/vDdata_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1_set1.npy\").reshape(4,1000,50001)[:,-1,:50000]\n",
    "true4_dend_nona = np.load(\"/media/hdd01/sklee/CA1_clust4-60_noNA/data/vDdata_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_noDendNa_Er0.5_Ir7.4_random_NR_rep1000_stimseed1_set1.npy\").reshape(4,1000,50001)[:,-1,:50000]\n",
    "true4_dend = true4_dend_na - true4_dend_nona\n",
    "true4_dend_nona = true4_dend_nona - np.mean(true4_dend_nona, 1).reshape(-1,1)\n",
    "gru4_nona_subout -= np.mean(gru4_nona_subout, 1).reshape(-1,1)\n",
    "gru4_diff_subout -= np.mean(gru4_diff_subout, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7df60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29970/2949891472.py:16: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(2000):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9944b4d47f0406294d785a542b2442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C4_clust_idx = np.zeros((2000))\n",
    "C8_clust_idx = np.zeros((2000))\n",
    "C12_clust_idx = np.zeros((2000))\n",
    "\n",
    "for i in range(4):\n",
    "    C4_clust_idx[880+60*i:880+60*(i+1)] = i+1\n",
    "for i in range(8):\n",
    "    C8_clust_idx[880+30*i:880+30*(i+1)] = i+1\n",
    "for i in range(12):\n",
    "    C12_clust_idx[880+20*i:880+20*(i+1)] = i+1\n",
    "    \n",
    "C4_clust = np.zeros((2000,2000))\n",
    "C8_clust = np.zeros((2000,2000))\n",
    "C12_clust = np.zeros((2000,2000))\n",
    "\n",
    "for i in tnrange(2000):\n",
    "    for j in range(2000):\n",
    "        if C4_clust_idx[i] != C4_clust_idx[j]:\n",
    "            C4_clust[i,j] = 1\n",
    "            C4_clust[j,i] = 1\n",
    "        if C8_clust_idx[i] != C8_clust_idx[j]:\n",
    "            C8_clust[i,j] = 1\n",
    "            C8_clust[j,i] = 1\n",
    "        if C12_clust_idx[i] != C12_clust_idx[j]:\n",
    "            C12_clust[i,j] = 1\n",
    "            C12_clust[j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef02076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29970/2302474722.py:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(2000):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d629e1d0d634b9f82c40fd8a54141f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C4_dist = np.zeros((2000,2000))\n",
    "C8_dist = np.zeros((2000,2000))\n",
    "C12_dist = np.zeros((2000,2000))\n",
    "\n",
    "for i in tnrange(2000):\n",
    "    for j in range(2000):\n",
    "        C4_dist[i,j] = np.abs(C4_dist_raw[i] - C4_dist_raw[j])\n",
    "        C8_dist[i,j] = np.abs(C8_dist_raw[i] - C8_dist_raw[j])\n",
    "        C12_dist[i,j] = np.abs(C12_dist_raw[i] - C12_dist_raw[j])\n",
    "\n",
    "#############\n",
    "#############\n",
    "        \n",
    "C4_dist_bin_nona = np.zeros((2000*2000))\n",
    "C8_dist_bin_nona = np.zeros((2000*2000))\n",
    "C12_dist_bin_nona = np.zeros((2000*2000))\n",
    "C4_dist_bin_diff = np.zeros((2000*2000))\n",
    "C8_dist_bin_diff = np.zeros((2000*2000))\n",
    "C12_dist_bin_diff = np.zeros((2000*2000))\n",
    "\n",
    "thresh_dist_nona = np.asarray([96.21105791219199,201.4570872069728,224.00383024626842])\n",
    "thresh_dist_diff = np.asarray([0.0014969594585352297, 0.0014969594585352297,0.0014969594585352297])\n",
    "\n",
    "C4_thresh_dist_nona_idx = np.where(C4_dist.flatten() >= thresh_dist_nona[0])[0]\n",
    "C8_thresh_dist_nona_idx = np.where(C8_dist.flatten() >= thresh_dist_nona[1])[0]\n",
    "C12_thresh_dist_nona_idx = np.where(C12_dist.flatten() >= thresh_dist_nona[2])[0]\n",
    "C4_thresh_dist_diff_idx = np.where(C4_dist.flatten() >= thresh_dist_diff[0])[0]\n",
    "C8_thresh_dist_diff_idx = np.where(C8_dist.flatten() >= thresh_dist_diff[1])[0]\n",
    "C12_thresh_dist_diff_idx = np.where(C12_dist.flatten() >= thresh_dist_diff[2])[0]\n",
    "\n",
    "C4_dist_bin_nona[C4_thresh_dist_nona_idx] = 1\n",
    "C8_dist_bin_nona[C8_thresh_dist_nona_idx] = 1\n",
    "C12_dist_bin_nona[C12_thresh_dist_nona_idx] = 1\n",
    "C4_dist_bin_diff[C4_thresh_dist_diff_idx] = 1\n",
    "C8_dist_bin_diff[C8_thresh_dist_diff_idx] = 1\n",
    "C12_dist_bin_diff[C12_thresh_dist_diff_idx] = 1\n",
    "\n",
    "C4_dist_bin_nona = C4_dist_bin_nona.reshape((2000,2000))\n",
    "C8_dist_bin_nona = C8_dist_bin_nona.reshape((2000,2000))\n",
    "C12_dist_bin_nona = C12_dist_bin_nona.reshape((2000,2000))\n",
    "C4_dist_bin_diff = C4_dist_bin_diff.reshape((2000,2000))\n",
    "C8_dist_bin_diff = C8_dist_bin_diff.reshape((2000,2000))\n",
    "C12_dist_bin_diff = C12_dist_bin_diff.reshape((2000,2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d294cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29970/1834695906.py:23: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(3):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e7c3697868439fb930da3e53539587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = np.triu_indices(2000, k=0)\n",
    "x_part, y_part = np.triu_indices(240, k=0)\n",
    "x_part += 880\n",
    "y_part += 880\n",
    "\n",
    "corr_type = \"spearman\"\n",
    "\n",
    "within_corrs_weighted = np.zeros((rep_no*(rep_no-1)//2,9))\n",
    "across_corrs_weighted = np.zeros((rep_no**2,3))\n",
    "dist_corrs_weighted = np.zeros((rep_no,9))\n",
    "clust_corrs_weighted = np.zeros((rep_no,9))\n",
    "\n",
    "C4_diff_scale_mat_all = np.matmul(C4_diff_scale_all.reshape(rep_no,-1,1), C4_diff_scale_all.reshape(rep_no,1,-1))\n",
    "C4_nona_scale_mat_all = np.matmul(C4_nona_scale_all.reshape(rep_no,-1,1), C4_nona_scale_all.reshape(rep_no,1,-1))\n",
    "C8_diff_scale_mat_all = np.matmul(C8_diff_scale_all.reshape(rep_no,-1,1), C8_diff_scale_all.reshape(rep_no,1,-1))\n",
    "C8_nona_scale_mat_all = np.matmul(C8_nona_scale_all.reshape(rep_no,-1,1), C8_nona_scale_all.reshape(rep_no,1,-1))\n",
    "C12_diff_scale_mat_all = np.matmul(C12_diff_scale_all.reshape(rep_no,-1,1), C12_diff_scale_all.reshape(rep_no,1,-1))\n",
    "C12_nona_scale_mat_all = np.matmul(C12_nona_scale_all.reshape(rep_no,-1,1), C12_nona_scale_all.reshape(rep_no,1,-1))\n",
    "C4_rand_scale_mat_all = np.matmul(C4_rand_scale_all.reshape(rep_no,-1,1), C4_rand_scale_all.reshape(rep_no,1,-1))\n",
    "C8_rand_scale_mat_all = np.matmul(C8_rand_scale_all.reshape(rep_no,-1,1), C8_rand_scale_all.reshape(rep_no,1,-1))\n",
    "C12_rand_scale_mat_all = np.matmul(C12_rand_scale_all.reshape(rep_no,-1,1), C12_rand_scale_all.reshape(rep_no,1,-1))\n",
    "\n",
    "for i in tnrange(3):\n",
    "    if i == 0:\n",
    "        dist_mat = C4_dist\n",
    "        clust_mat = C4_clust\n",
    "        diff_mat_all = C4_diff_all\n",
    "        nona_mat_all = C4_nona_all\n",
    "        diff_scale_mat_all = C4_diff_scale_mat_all\n",
    "        nona_scale_mat_all = C4_nona_scale_mat_all\n",
    "        rand_mat_all = C4_rand_all\n",
    "        rand_scale_mat_all = C4_rand_scale_mat_all\n",
    "        dist_mat_bin_nona = C4_dist_bin_nona\n",
    "        dist_mat_bin_diff = C4_dist_bin_diff\n",
    "\n",
    "    elif i == 1:\n",
    "        dist_mat = C8_dist\n",
    "        clust_mat = C8_clust\n",
    "        diff_mat_all = C8_diff_all\n",
    "        nona_mat_all = C8_nona_all\n",
    "        diff_scale_mat_all = C8_diff_scale_mat_all\n",
    "        nona_scale_mat_all = C8_nona_scale_mat_all\n",
    "        rand_mat_all = C8_rand_all\n",
    "        rand_scale_mat_all = C8_rand_scale_mat_all\n",
    "        dist_mat_bin_nona = C8_dist_bin_nona\n",
    "        dist_mat_bin_diff = C8_dist_bin_diff\n",
    "\n",
    "    elif i == 2:\n",
    "        dist_mat = C12_dist\n",
    "        clust_mat = C12_clust\n",
    "        diff_mat_all = C12_diff_all\n",
    "        nona_mat_all = C12_nona_all\n",
    "        diff_scale_mat_all = C12_diff_scale_mat_all\n",
    "        nona_scale_mat_all = C12_nona_scale_mat_all\n",
    "        rand_mat_all = C12_rand_all\n",
    "        rand_scale_mat_all = C12_rand_scale_mat_all\n",
    "        dist_mat_bin_nona = C12_dist_bin_nona\n",
    "        dist_mat_bin_diff = C12_dist_bin_diff\n",
    "        \n",
    "    across_count = 0\n",
    "    within_count = 0\n",
    "    for j in range(rep_no):\n",
    "        for k in range(rep_no):\n",
    "            weight = diff_scale_mat_all[j][x,y] * nona_scale_mat_all[k][x,y]\n",
    "            across_corr_val = WeightedCorr(x=pd.Series(diff_mat_all[j][x,y]),\n",
    "                   y=pd.Series(nona_mat_all[k][x,y]),\n",
    "                   w=pd.Series(weight))(method=corr_type)\n",
    "            across_corrs_weighted[across_count,i] = across_corr_val\n",
    "            across_count += 1\n",
    "        for k in range(j+1,rep_no,1):\n",
    "            diff_weight = diff_scale_mat_all[j][x,y] * diff_scale_mat_all[k][x,y]\n",
    "            nona_weight = nona_scale_mat_all[j][x,y] * nona_scale_mat_all[k][x,y]\n",
    "            within_diff_corr_val = WeightedCorr(x=pd.Series(diff_mat_all[j][x,y]),\n",
    "                   y=pd.Series(diff_mat_all[k][x,y]),\n",
    "                   w=pd.Series(diff_weight))(method=corr_type)\n",
    "            within_nona_corr_val = WeightedCorr(x=pd.Series(nona_mat_all[j][x,y]),\n",
    "                   y=pd.Series(nona_mat_all[k][x,y]),\n",
    "                   w=pd.Series(nona_weight))(method=corr_type)\n",
    "            within_corrs_weighted[within_count,i*2] = within_nona_corr_val\n",
    "            within_corrs_weighted[within_count,i*2+1] = within_diff_corr_val\n",
    "            \n",
    "            rand_weight = rand_scale_mat_all[j][x,y] * rand_scale_mat_all[k][x,y]\n",
    "            within_rand_corr_val = WeightedCorr(x=pd.Series(rand_mat_all[j][x,y]),\n",
    "                   y=pd.Series(rand_mat_all[k][x,y]),\n",
    "                   w=pd.Series(rand_weight))(method=corr_type)\n",
    "            within_corrs_weighted[within_count,i+6] = within_rand_corr_val            \n",
    "            \n",
    "            within_count += 1\n",
    "        \n",
    "        nona_weight = nona_scale_mat_all[j][x,y]\n",
    "        diff_weight = diff_scale_mat_all[j][x,y]\n",
    "        \n",
    "        dist_nona_corr_val = WeightedCorr(x=pd.Series(dist_mat[x,y]),\n",
    "                   y=pd.Series(nona_mat_all[j][x,y]),\n",
    "                   w=pd.Series(nona_weight))(method=corr_type)\n",
    "        dist_diff_corr_val = WeightedCorr(x=pd.Series(dist_mat[x,y]),\n",
    "                   y=pd.Series(diff_mat_all[j][x,y]),\n",
    "                   w=pd.Series(diff_weight))(method=corr_type)\n",
    "        \"\"\"\n",
    "        ##################\n",
    "        dist_nona_corr_val = WeightedCorr(x=pd.Series(dist_mat_bin_nona[x,y]),\n",
    "                   y=pd.Series(nona_mat_all[j][x,y]),\n",
    "                   w=pd.Series(nona_weight))(method=corr_type)\n",
    "        dist_diff_corr_val = WeightedCorr(x=pd.Series(dist_mat_bin_diff[x,y]),\n",
    "                   y=pd.Series(diff_mat_all[j][x,y]),\n",
    "                   w=pd.Series(diff_weight))(method=corr_type)\n",
    "        ##################\n",
    "        \"\"\"\n",
    "        dist_corrs_weighted[j,i*2] = dist_nona_corr_val\n",
    "        dist_corrs_weighted[j,i*2+1] = dist_diff_corr_val\n",
    "        rand_weight = rand_scale_mat_all[j][x,y]\n",
    "        dist_rand_corr_val = WeightedCorr(x=pd.Series(dist_mat[x,y]),\n",
    "                   y=pd.Series(rand_mat_all[j][x,y]),\n",
    "                   w=pd.Series(rand_weight))(method=corr_type)\n",
    "        dist_corrs_weighted[j,i+6] = dist_rand_corr_val\n",
    "        \n",
    "        nona_weight_part = nona_scale_mat_all[j][x_part,y_part]\n",
    "        diff_weight_part = diff_scale_mat_all[j][x_part,y_part]\n",
    "        clust_nona_corr_val = WeightedCorr(x=pd.Series(clust_mat[x_part,y_part]),\n",
    "                   y=pd.Series(nona_mat_all[j][x_part,y_part]),\n",
    "                   w=pd.Series(nona_weight_part))(method=corr_type)\n",
    "        clust_diff_corr_val = WeightedCorr(x=pd.Series(clust_mat[x_part,y_part]),\n",
    "                   y=pd.Series(diff_mat_all[j][x_part,y_part]),\n",
    "                   w=pd.Series(diff_weight_part))(method=corr_type)\n",
    "        clust_corrs_weighted[j,i*2] = clust_nona_corr_val\n",
    "        clust_corrs_weighted[j,i*2+1] = clust_diff_corr_val\n",
    "        rand_weight_part = rand_scale_mat_all[j][x_part,y_part]\n",
    "        clust_rand_corr_val = WeightedCorr(x=pd.Series(clust_mat[x_part,y_part]),\n",
    "                   y=pd.Series(rand_mat_all[j][x_part,y_part]),\n",
    "                   w=pd.Series(rand_weight_part))(method=corr_type)\n",
    "        clust_corrs_weighted[j,i+6] = clust_rand_corr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92347471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29970/4231668019.py:46: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(rep_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b02878016345ef91f32ffefcc3bf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C4_diff_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "C4_nona_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "C8_diff_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "C8_nona_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "C12_diff_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "C12_nona_rep_corr_weighted = np.zeros((rep_no, rep_no))\n",
    "\n",
    "within_count = 0\n",
    "for i in range(rep_no):\n",
    "    for j in range(i+1,rep_no,1):\n",
    "        C4_nona_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 0]\n",
    "        C4_nona_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 0]\n",
    "        C4_diff_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 1]\n",
    "        C4_diff_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 1]\n",
    "        C8_nona_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 2]\n",
    "        C8_nona_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 2]\n",
    "        C8_diff_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 3]\n",
    "        C8_diff_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 3]\n",
    "        C12_nona_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 4]\n",
    "        C12_nona_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 4]\n",
    "        C12_diff_rep_corr_weighted[i,j] = within_corrs_weighted[within_count, 5]\n",
    "        C12_diff_rep_corr_weighted[j,i] = within_corrs_weighted[within_count, 5]\n",
    "        \n",
    "        within_count += 1\n",
    "\n",
    "C4_diff_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "C4_nona_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "C8_diff_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "C8_nona_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "C12_diff_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "C12_nona_heatmap_weighted = np.zeros((rep_no+3, rep_no))\n",
    "\n",
    "C4_nona_heatmap_weighted[:rep_no,:] = C4_nona_rep_corr_weighted\n",
    "C4_nona_heatmap_weighted[-3,:] = dist_corrs_weighted[:,0]\n",
    "C4_diff_heatmap_weighted[:rep_no,:] = C4_diff_rep_corr_weighted\n",
    "C4_diff_heatmap_weighted[-3,:] = dist_corrs_weighted[:,1]\n",
    "C8_nona_heatmap_weighted[:rep_no,:] = C8_nona_rep_corr_weighted\n",
    "C8_nona_heatmap_weighted[-3,:] = dist_corrs_weighted[:,2]\n",
    "C8_diff_heatmap_weighted[:rep_no,:] = C8_diff_rep_corr_weighted\n",
    "C8_diff_heatmap_weighted[-3,:] = dist_corrs_weighted[:,3]\n",
    "C12_nona_heatmap_weighted[:rep_no,:] = C12_nona_rep_corr_weighted\n",
    "C12_nona_heatmap_weighted[-3,:] = dist_corrs_weighted[:,4]\n",
    "C12_diff_heatmap_weighted[:rep_no,:] = C12_diff_rep_corr_weighted\n",
    "C12_diff_heatmap_weighted[-3,:] = dist_corrs_weighted[:,5]\n",
    "\n",
    "for i in tnrange(rep_no):\n",
    "    C4_nona_rand = WeightedCorr(x=pd.Series(C4_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C4_nona_all[i][x,y]),\n",
    "                   w=pd.Series(C4_nona_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    C4_diff_rand = WeightedCorr(x=pd.Series(C4_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C4_diff_all[i][x,y]),\n",
    "                   w=pd.Series(C4_diff_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    C8_nona_rand = WeightedCorr(x=pd.Series(C8_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C4_nona_all[i][x,y]),\n",
    "                   w=pd.Series(C4_nona_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    C8_diff_rand = WeightedCorr(x=pd.Series(C8_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C4_diff_all[i][x,y]),\n",
    "                   w=pd.Series(C4_diff_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    C12_nona_rand = WeightedCorr(x=pd.Series(C12_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C12_nona_all[i][x,y]),\n",
    "                   w=pd.Series(C12_nona_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    C12_diff_rand = WeightedCorr(x=pd.Series(C12_rand_all[i][x,y]),\n",
    "                   y=pd.Series(C12_diff_all[i][x,y]),\n",
    "                   w=pd.Series(C12_diff_scale_mat_all[i][x,y]))(method=corr_type)\n",
    "    \n",
    "    C4_nona_clust = WeightedCorr(x=pd.Series(C4_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C4_nona_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C4_nona_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    C4_diff_clust = WeightedCorr(x=pd.Series(C4_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C4_diff_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C4_diff_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    C8_nona_clust = WeightedCorr(x=pd.Series(C8_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C4_nona_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C4_nona_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    C8_diff_clust = WeightedCorr(x=pd.Series(C8_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C4_diff_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C4_diff_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    C12_nona_clust = WeightedCorr(x=pd.Series(C12_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C12_nona_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C12_nona_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    C12_diff_clust = WeightedCorr(x=pd.Series(C12_clust[x_part,y_part]),\n",
    "                   y=pd.Series(C12_diff_all[i][x_part,y_part]),\n",
    "                   w=pd.Series(C12_diff_scale_mat_all[i][x_part,y_part]))(method=corr_type)\n",
    "    \n",
    "    C4_nona_heatmap_weighted[-1,i] = C4_nona_rand\n",
    "    C4_diff_heatmap_weighted[-1,i] = C4_diff_rand\n",
    "    C8_nona_heatmap_weighted[-1,i] = C8_nona_rand\n",
    "    C8_diff_heatmap_weighted[-1,i] = C8_diff_rand\n",
    "    C12_nona_heatmap_weighted[-1,i] = C12_nona_rand\n",
    "    C12_diff_heatmap_weighted[-1,i] = C12_diff_rand\n",
    "    C4_nona_heatmap_weighted[-2,i] = C4_nona_clust\n",
    "    C4_diff_heatmap_weighted[-2,i] = C4_diff_clust\n",
    "    C8_nona_heatmap_weighted[-2,i] = C8_nona_clust\n",
    "    C8_diff_heatmap_weighted[-2,i] = C8_diff_clust\n",
    "    C12_nona_heatmap_weighted[-2,i] = C12_nona_clust\n",
    "    C12_diff_heatmap_weighted[-2,i] = C12_diff_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4595c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "corr_norm = np.asarray([0.81506, 0.80524, 0.71393, 0.74866, 0.56864, 0.61865])\n",
    "dist_corrs_weighted[:,:-3] /= corr_norm.reshape(1,-1)\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52931967",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0e169d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2993991382.py, line 131)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_29970/2993991382.py\"\u001b[0;36m, line \u001b[0;32m131\u001b[0m\n\u001b[0;31m    ax3.set_ylabel(correlation\")\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['font.sans-serif'] = \"Arial\"\n",
    "mpl.rcParams['font.family'] = \"sans-serif\"\n",
    "plt.rcParams['font.size'] = '13'\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (14,7))\n",
    "gs = fig.add_gridspec(12,4, wspace=0.5, hspace=0.35)\n",
    "ax1 = fig.add_subplot(gs[:5,2:4])\n",
    "#ax2 = fig.add_subplot(gs[:5,3])\n",
    "ax3 = fig.add_subplot(gs[7:,2])\n",
    "ax4 = fig.add_subplot(gs[7:,3])\n",
    "ax5 = fig.add_subplot(gs[:4,0])\n",
    "ax6 = fig.add_subplot(gs[:4,1])\n",
    "ax7 = fig.add_subplot(gs[4:8,0])\n",
    "ax8 = fig.add_subplot(gs[4:8,1])\n",
    "ax9 = fig.add_subplot(gs[8:,0])\n",
    "ax10 = fig.add_subplot(gs[8:,1])\n",
    "\n",
    "\n",
    "colors=[\"blue\", \"red\",\n",
    "        \"blue\", \"red\",\n",
    "        \"blue\", \"red\"]\n",
    "cap_colors=[\"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\"]\n",
    "bp = ax1.boxplot(within_corrs_weighted[:,:-3], positions=[1,2,5,6,9,10], widths=0.6, patch_artist=True)\n",
    "for i in range(6):\n",
    "    plt.setp(bp['boxes'][i], facecolor=colors[i])\n",
    "    plt.setp(bp['boxes'][i], alpha=0.5)\n",
    "    plt.setp(bp[\"fliers\"][i], markeredgecolor=colors[i])\n",
    "    plt.setp(bp[\"boxes\"][i], color=colors[i])\n",
    "    plt.setp(bp[\"medians\"][i], color=colors[i])\n",
    "for i in range(12):\n",
    "    plt.setp(bp['whiskers'][i], color=cap_colors[i])\n",
    "    plt.setp(bp['caps'][i], color=cap_colors[i])\n",
    "\n",
    "ax1.fill_between(np.arange(0.8,3.3,0.01), np.mean(within_corrs_weighted[:,-3])-np.std(within_corrs_weighted[:,-3]),\n",
    "                 np.mean(within_corrs_weighted[:,-3])+np.std(within_corrs_weighted[:,-3]), color=\"gray\")\n",
    "ax1.fill_between(np.arange(4.8,7.3,0.01), np.mean(within_corrs_weighted[:,-2])-np.std(within_corrs_weighted[:,-2]),\n",
    "                 np.mean(within_corrs_weighted[:,-2])+np.std(within_corrs_weighted[:,-2]), color=\"gray\")\n",
    "ax1.fill_between(np.arange(8.8,11.3,0.01), np.mean(within_corrs_weighted[:,-1])-np.std(within_corrs_weighted[:,-1]),\n",
    "                 np.mean(within_corrs_weighted[:,-1])+np.std(within_corrs_weighted[:,-1]), color=\"gray\")\n",
    "    \n",
    "hB = ax1.scatter(1,1,c='blue', marker=\"s\")\n",
    "hR = ax1.scatter(1,1,c='red', marker=\"s\")\n",
    "hP = ax1.scatter(1,1,c='purple', marker=\"s\")\n",
    "ax1.legend((hB, hR, hP),('within $\\mathregular{v_{other}}$',\n",
    "                         'within $\\mathregular{v_{Na}}$',\n",
    "                        'b/w $\\mathregular{v_{other}}$ & $\\mathregular{v_{Na}}$'),\n",
    "           frameon=False, fontsize=10,\n",
    "          loc=(0.525,0.6))\n",
    "hB.set_visible(False)\n",
    "hR.set_visible(False)\n",
    "hP.set_visible(False)\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "bp1 = ax1.boxplot(across_corrs_weighted, positions=[3,7,11], widths=0.6, patch_artist=True)\n",
    "colors=[\"purple\", \"purple\", \"purple\"]\n",
    "cap_colors=[\"purple\", \"purple\", \"purple\", \"purple\", \"purple\", \"purple\"]\n",
    "for i in range(across_corrs_weighted.shape[1]):\n",
    "    plt.setp(bp1['boxes'][i], facecolor=colors[i])\n",
    "    plt.setp(bp1['boxes'][i], alpha=0.5)\n",
    "    plt.setp(bp1[\"fliers\"][i], markeredgecolor=colors[i])\n",
    "    plt.setp(bp1[\"boxes\"][i], color=colors[i])\n",
    "    plt.setp(bp1[\"medians\"][i], color=colors[i])\n",
    "for i in range(across_corrs_weighted.shape[1]*2):\n",
    "    plt.setp(bp1['whiskers'][i], color=cap_colors[i])\n",
    "    plt.setp(bp1['caps'][i], color=cap_colors[i])\n",
    "    \n",
    "\n",
    "ax1.set_ylim(-0.2,1)\n",
    "ax1.set_yticks([-0.2,0.2,0.6,1.0])\n",
    "ax1.spines.right.set_visible(False)\n",
    "ax1.spines.top.set_visible(False)\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax1.set_xticks([2, 6, 10])\n",
    "ax1.set_xticklabels([\"4\", \"8\", \"12\"])\n",
    "ax1.tick_params(axis=\"x\", length=0)\n",
    "ax1.set_xlabel(\"no. of clusters\")\n",
    "ax1.set_ylabel(\"correlation\")\n",
    "ax1.set_title(\"correlation between architectures\",\n",
    "             fontsize=13)\n",
    "    \n",
    "\"\"\"\n",
    "ax2.set_ylim(-0.2,1)\n",
    "ax2.set_yticks([-0.2,0.2,0.6,1.0])\n",
    "ax2.spines.right.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax2.spines.bottom.set_visible(False)\n",
    "ax2.set_xticks([1, 2, 3])\n",
    "ax2.set_xticklabels([\"4\", \"8\", \"12\"])\n",
    "ax2.tick_params(axis=\"x\", length=0)\n",
    "ax2.set_xlabel(\"no. of clusters\")\n",
    "ax2.set_title(\"correlation between architectures\\nof $\\mathregular{v_{other}}$ and $\\mathregular{v_{Na}}$\",\n",
    "             fontsize=13)\n",
    "\"\"\"\n",
    "\n",
    "####################################\n",
    "bp = ax3.boxplot(dist_corrs_weighted[:,:-3], positions=[1,2,4,5,7,8], widths=0.6, patch_artist=True)\n",
    "colors=[\"blue\", \"red\", \"blue\", \"red\", \"blue\", \"red\"]\n",
    "cap_colors=[\"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\"]\n",
    "for i in range(dist_corrs_weighted[:,:-3].shape[1]):\n",
    "    plt.setp(bp['boxes'][i], facecolor=colors[i])\n",
    "    plt.setp(bp['boxes'][i], alpha=0.5)\n",
    "    plt.setp(bp[\"fliers\"][i], markeredgecolor=colors[i])\n",
    "    plt.setp(bp[\"boxes\"][i], color=colors[i])\n",
    "    plt.setp(bp[\"medians\"][i], color=colors[i])\n",
    "for i in range(dist_corrs_weighted[:,:-3].shape[1]*2):\n",
    "    plt.setp(bp['whiskers'][i], color=cap_colors[i])\n",
    "    plt.setp(bp['caps'][i], color=cap_colors[i])\n",
    "ax3.fill_between(np.arange(0.8,2.3,0.01), np.mean(dist_corrs_weighted[:,-3])-np.std(dist_corrs_weighted[:,-3]),\n",
    "                 np.mean(dist_corrs_weighted[:,-3])+np.std(dist_corrs_weighted[:,-3]), color=\"gray\")\n",
    "ax3.fill_between(np.arange(3.8,5.3,0.01), np.mean(dist_corrs_weighted[:,-2])-np.std(dist_corrs_weighted[:,-2]),\n",
    "                 np.mean(dist_corrs_weighted[:,-2])+np.std(dist_corrs_weighted[:,-2]), color=\"gray\")\n",
    "ax3.fill_between(np.arange(6.8,8.3,0.01), np.mean(dist_corrs_weighted[:,-1])-np.std(dist_corrs_weighted[:,-1]),\n",
    "                 np.mean(dist_corrs_weighted[:,-1])+np.std(dist_corrs_weighted[:,-1]), color=\"gray\")\n",
    "\n",
    "ax3.set_ylim(-0.2,1)\n",
    "ax3.set_yticks([-0.2,0.2,0.6,1.0])\n",
    "ax3.spines.right.set_visible(False)\n",
    "ax3.spines.top.set_visible(False)\n",
    "ax3.spines.bottom.set_visible(False)\n",
    "ax3.set_xticks([1.5, 4.5, 7.5])\n",
    "ax3.set_xticklabels([\"4\", \"8\", \"12\"])\n",
    "ax3.tick_params(axis=\"x\", length=0)\n",
    "ax3.set_xlabel(\"no. of clusters\")\n",
    "ax3.set_ylabel(\"correlation\")\n",
    "ax3.set_title(\"correlation between architecture\\nand somatic distance\",\n",
    "             fontsize=13)\n",
    "\n",
    "####################################\n",
    "bp = ax4.boxplot(clust_corrs_weighted[:,:-3], positions=[1,2,4,5,7,8], widths=0.6, patch_artist=True)\n",
    "colors=[\"blue\", \"red\", \"blue\", \"red\", \"blue\", \"red\"]\n",
    "cap_colors=[\"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\",\n",
    "           \"blue\", \"blue\", \"red\", \"red\"]\n",
    "for i in range(clust_corrs_weighted[:,:-3].shape[1]):\n",
    "    plt.setp(bp['boxes'][i], facecolor=colors[i])\n",
    "    plt.setp(bp['boxes'][i], alpha=0.5)\n",
    "    plt.setp(bp[\"fliers\"][i], markeredgecolor=colors[i])\n",
    "    plt.setp(bp[\"boxes\"][i], color=colors[i])\n",
    "    plt.setp(bp[\"medians\"][i], color=colors[i])\n",
    "for i in range(clust_corrs_weighted[:,:-3].shape[1]*2):\n",
    "    plt.setp(bp['whiskers'][i], color=cap_colors[i])\n",
    "    plt.setp(bp['caps'][i], color=cap_colors[i])\n",
    "ax4.fill_between(np.arange(0.8,2.3,0.01), np.mean(clust_corrs_weighted[:,-3])-np.std(clust_corrs_weighted[:,-3]),\n",
    "                 np.mean(clust_corrs_weighted[:,-3])+np.std(clust_corrs_weighted[:,-3]), color=\"gray\")\n",
    "ax4.fill_between(np.arange(3.8,5.3,0.01), np.mean(clust_corrs_weighted[:,-2])-np.std(clust_corrs_weighted[:,-2]),\n",
    "                 np.mean(clust_corrs_weighted[:,-2])+np.std(clust_corrs_weighted[:,-2]), color=\"gray\")\n",
    "ax4.fill_between(np.arange(6.8,8.3,0.01), np.mean(clust_corrs_weighted[:,-1])-np.std(clust_corrs_weighted[:,-1]),\n",
    "                 np.mean(clust_corrs_weighted[:,-1])+np.std(clust_corrs_weighted[:,-1]), color=\"gray\")\n",
    "\n",
    "ax4.set_ylim(-0.2,1)\n",
    "ax4.set_yticks([-0.2,0.2,0.6,1.0])\n",
    "ax4.spines.right.set_visible(False)\n",
    "ax4.spines.top.set_visible(False)\n",
    "ax4.spines.bottom.set_visible(False)\n",
    "ax4.set_xticks([1.5, 4.5, 7.5])\n",
    "ax4.set_xticklabels([\"4\", \"8\", \"12\"])\n",
    "ax4.tick_params(axis=\"x\", length=0)\n",
    "ax4.set_xlabel(\"no. of clusters\")\n",
    "ax4.set_title(\"correlation between\\narchitecture and clusters\",\n",
    "             fontsize=13)\n",
    "\n",
    "################################\n",
    "\n",
    "ax5.plot(true4_dend[0][17000:20000]+25, linewidth=1.5, color=\"black\", label=\"cluster 1\")\n",
    "ax5.plot(true4_dend[2][17000:20000]+50, linewidth=1.5, color=\"black\", label=\"cluster 3\", linestyle=\"--\")\n",
    "ax5.plot(gru4_diff_subout[0][17000:20000]*50, linewidth=1.5, color=\"#ff0000\", alpha=0.8, label=\"subunit 1\")\n",
    "ax5.set_ylabel(\"cluster 1 & 3 with\\nsubunit 1\")\n",
    "ax5.set_title(\"timepoint 1\", fontsize=13)\n",
    "ax5.margins(x=0.005, y=0.005)\n",
    "ax5.legend(loc=(0.85,0.55), frameon=False, fontsize=10)\n",
    "\n",
    "ax6.plot(true4_dend[0][22500:25500]+25, linewidth=1.5, color=\"black\")\n",
    "ax6.plot(true4_dend[2][22500:25500]+50, linewidth=1.5, color=\"black\", linestyle=\"--\")\n",
    "ax6.plot(gru4_diff_subout[0][22500:25500]*50, linewidth=1.5, color=\"#ff0000\", alpha=0.8)\n",
    "ax6.set_title(\"timepoint 2\", fontsize=13)\n",
    "ax6.margins(x=0.005, y=0.005)\n",
    "\n",
    "ax7.plot(true4_dend[1][17000:20000]+25, linewidth=1.5, color=\"black\", label=\"cluster 2\")\n",
    "ax7.plot(gru4_diff_subout[4][17000:20000]*50, linewidth=1.5, color=\"#ffa200\", alpha=0.8, label=\"subunit 5\")\n",
    "ax7.set_ylabel(\"cluster 2 with\\nsubunit 5\")\n",
    "#ax7.set_title(\"timepoint 1\", fontsize=13)\n",
    "ax7.margins(x=0.005, y=0.005)\n",
    "ax7.legend(loc=(0.85,0.55), frameon=False, fontsize=10)\n",
    "\n",
    "ax8.plot(true4_dend[1][22500:25500]+25, linewidth=1.5, color=\"black\")\n",
    "ax8.plot(gru4_diff_subout[4][22500:25500]*50, linewidth=1.5, color=\"#ffa200\", alpha=0.8)\n",
    "#ax8.set_title(\"timepoint 2\", fontsize=13)\n",
    "ax8.margins(x=0.005, y=0.005)\n",
    "\n",
    "ax9.plot(true4_dend[2][17000:20000]+25, linewidth=1.5, color=\"black\", label=\"cluster 3\")\n",
    "ax9.plot(gru4_diff_subout[2][17000:20000]*50, linewidth=1.5, color=\"#00ff80\", alpha=0.8, label=\"subunit 3\")\n",
    "ax9.legend(loc=(0.85,0.55), frameon=False, fontsize=10)\n",
    "ax9.set_ylabel(\"cluster 3 with\\nsubunit 3\")\n",
    "#ax9.set_title(\"timepoint 1\", fontsize=13)\n",
    "#ax9.margins(x=0.005, y=0.005)\n",
    "\n",
    "ax10.plot(true4_dend[2][22500:25500]+25, linewidth=1.5, color=\"black\")\n",
    "ax10.plot(gru4_diff_subout[2][22500:25500]*50, linewidth=1.5, color=\"#00ff80\", alpha=0.8)\n",
    "ax10.margins(x=0.005, y=0.005)\n",
    "#ax10.set_title(\"timepoint 2\", fontsize=13)\n",
    "\n",
    "ax_list = [ax5, ax6, ax7, ax8, ax9, ax10]\n",
    "\n",
    "for ax in ax_list:\n",
    "    ax.spines.right.set_visible(False)\n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.spines.bottom.set_visible(False)\n",
    "    ax.spines.left.set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim(-20,80)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig(\"/home/sklee/dendrite/fig9/fig9_raw_bin.pdf\", bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41920e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba7452d3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# thresh find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e056d71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gap_no = 50\n",
    "x, y = np.triu_indices(2000, k=0)\n",
    "x_part, y_part = np.triu_indices(240, k=0)\n",
    "corr_vals = np.zeros((rep_no, gap_no, 3))\n",
    "distance_matrix = C12_dist\n",
    "unique_dist = np.unique(distance_matrix)\n",
    "\n",
    "for n in range(rep_no):\n",
    "    weight_matrix = C12_nona_scale_mat_all[n][x,y]\n",
    "    subunit_matrix = C12_nona_all[n][x,y]\n",
    "\n",
    "    for i in tnrange(gap_no):\n",
    "        dist_bin = np.zeros((2000*2000))\n",
    "        thresh_gap = unique_dist.shape[0] // gap_no\n",
    "        thresh_gap = 20000 // gap_no\n",
    "        #thresh_gap = 1\n",
    "        idx = np.where(distance_matrix.flatten() >= unique_dist[i*thresh_gap+220000])[0]\n",
    "        dist_bin[idx] = 1\n",
    "        dist_bin = dist_bin.reshape((2000,2000))\n",
    "\n",
    "        dist_corr_val = WeightedCorr(x=pd.Series(dist_bin[x,y]),\n",
    "                       y=pd.Series(subunit_matrix),\n",
    "                       w=pd.Series(weight_matrix))(method='spearman')\n",
    "        corr_vals[n,i,0] = i*thresh_gap+220000\n",
    "        corr_vals[n,i,1] = unique_dist[i*thresh_gap+220000]\n",
    "        corr_vals[n,i,2] = dist_corr_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
