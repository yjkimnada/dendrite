{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tnrange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self, L_no, T_no, S_no):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.L_no = L_no\n",
    "        self.T_no = T_no\n",
    "        self.S_no = S_no\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        for i in range(L_no):\n",
    "            if i == 0:\n",
    "                modules.append(nn.Conv1d(in_channels=2,\n",
    "                                        out_channels=self.S_no,\n",
    "                                        kernel_size=self.T_no,\n",
    "                                        padding=(self.T_no-1)//2,\n",
    "                                        groups=2))\n",
    "                modules.append(nn.LeakyReLU())\n",
    "                \n",
    "            elif i == L_no-1:\n",
    "                modules.append(nn.Conv1d(in_channels=self.S_no,\n",
    "                                        out_channels=1,\n",
    "                                        kernel_size=self.T_no,\n",
    "                                        padding=(self.T_no-1)//2)\n",
    "                                          )\n",
    "            \n",
    "            else:\n",
    "                modules.append(nn.Conv1d(in_channels=self.S_no,\n",
    "                                        out_channels=self.S_no,\n",
    "                                        kernel_size=self.T_no,\n",
    "                                        padding=(self.T_no-1)//2,\n",
    "                                          groups=self.S_no))\n",
    "                modules.append(nn.LeakyReLU())\n",
    "                \n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, S_e, S_i):\n",
    "        S_e = torch.sum(S_e, 1)\n",
    "        S_i = torch.sum(S_i, 1)\n",
    "        \n",
    "        S = torch.hstack((S_e.reshape(-1,1), S_i.reshape(-1,1)))\n",
    "        S = S.T.unsqueeze(0)\n",
    "            \n",
    "        out = self.sequential(S)\n",
    "        out = torch.sigmoid(out.flatten())\n",
    "            \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_no = 6\n",
    "L_no = 4\n",
    "T_no = 151\n",
    "iter_no = 10000\n",
    "batch_size = 50000\n",
    "epoch_no = 15\n",
    "\n",
    "T_train = 60* 1000* 5\n",
    "T_test = 10* 1000 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/hdd01/sklee/\"\n",
    "experiment = \"clust4-60\"\n",
    "cell_type = \"CA1\"\n",
    "\n",
    "E_neural_file = \"Espikes_neural.npy\"\n",
    "I_neural_file = \"Ispikes_neural.npy\"\n",
    "Z_file = \"spk_loc.npy\"\n",
    "\n",
    "E_neural = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "I_neural = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+I_neural_file)\n",
    "Z = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+Z_file).flatten()\n",
    "\n",
    "E_neural = torch.from_numpy(E_neural)\n",
    "I_neural = torch.from_numpy(I_neural)\n",
    "Z = torch.from_numpy(Z)\n",
    "\n",
    "loss_weights = torch.ones(Z.shape[0]).cuda()\n",
    "Z_idx = torch.where(Z == 1)[0]\n",
    "for z in Z_idx:\n",
    "    loss_weights[z] *= 2\n",
    "    #loss_weights[z-10:z] *= 0.5\n",
    "    #loss_weights[z+1:z+10] *= 0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = Z[:T_train].cuda().float()\n",
    "Z_test = Z[T_train:T_train + T_test].cuda().float()\n",
    "loss_weights_train = loss_weights[:T_train].float()\n",
    "loss_weights_test = loss_weights[T_train:T_train+T_test].float()\n",
    "test_E_neural = E_neural[T_train:T_train+T_test].float().cuda()\n",
    "test_I_neural = I_neural[T_train:T_train+T_test].float().cuda()\n",
    "train_E_neural = E_neural[:T_train].float().cuda()\n",
    "train_I_neural = I_neural[:T_train].float().cuda()\n",
    "\n",
    "batch_no = (T_train - batch_size) * epoch_no\n",
    "train_idx = np.empty((epoch_no, T_train - batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(T_train - batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3643\n"
     ]
    }
   ],
   "source": [
    "model = TCN(L_no=L_no,\n",
    "            T_no=T_no,\n",
    "            S_no=S_no)\n",
    "model.cuda().float()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},\n",
    "            ], lr = 0.0005)\n",
    "\n",
    "bce_criterion = nn.BCELoss(reduction=\"none\")\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-df3d1fdb2156>:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a6063da4c647fdaf87c3d1a494ca16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BCE:  0.6907568573951721 GOOD:  692 BAD:  18729\n",
      "50 BCE:  0.03519582748413086 GOOD:  0 BAD:  0\n",
      "100 BCE:  0.02358625829219818 GOOD:  0 BAD:  0\n",
      "150 BCE:  0.023114724084734917 GOOD:  0 BAD:  0\n",
      "200 BCE:  0.021646102890372276 GOOD:  0 BAD:  0\n",
      "250 BCE:  0.017256680876016617 GOOD:  0 BAD:  0\n",
      "300 BCE:  0.016147589311003685 GOOD:  0 BAD:  0\n",
      "350 BCE:  0.01641637086868286 GOOD:  0 BAD:  0\n",
      "400 BCE:  0.016081979498267174 GOOD:  0 BAD:  0\n",
      "450 BCE:  0.016022788360714912 GOOD:  0 BAD:  0\n",
      "500 BCE:  0.01623048633337021 GOOD:  0 BAD:  0\n",
      "550 BCE:  0.015951091423630714 GOOD:  0 BAD:  0\n",
      "600 BCE:  0.016077497974038124 GOOD:  0 BAD:  0\n",
      "650 BCE:  0.01587727665901184 GOOD:  0 BAD:  0\n",
      "700 BCE:  0.015911336988210678 GOOD:  0 BAD:  0\n",
      "750 BCE:  0.01582174561917782 GOOD:  0 BAD:  0\n",
      "800 BCE:  0.015972783789038658 GOOD:  0 BAD:  0\n",
      "850 BCE:  0.015953581780195236 GOOD:  0 BAD:  0\n",
      "900 BCE:  0.015752548351883888 GOOD:  0 BAD:  0\n",
      "950 BCE:  0.01602337695658207 GOOD:  0 BAD:  0\n",
      "1000 BCE:  0.015776189044117928 GOOD:  0 BAD:  0\n",
      "1050 BCE:  0.015951208770275116 GOOD:  0 BAD:  0\n",
      "1100 BCE:  0.01584237813949585 GOOD:  0 BAD:  0\n",
      "1150 BCE:  0.015692824497818947 GOOD:  0 BAD:  0\n",
      "1200 BCE:  0.015621684491634369 GOOD:  0 BAD:  0\n",
      "1250 BCE:  0.015695180743932724 GOOD:  0 BAD:  0\n",
      "1300 BCE:  0.016193369403481483 GOOD:  0 BAD:  0\n",
      "1350 BCE:  0.015695007517933846 GOOD:  0 BAD:  0\n",
      "1400 BCE:  0.015784157440066338 GOOD:  0 BAD:  0\n",
      "1450 BCE:  0.015780124813318253 GOOD:  0 BAD:  0\n",
      "1500 BCE:  0.015795566141605377 GOOD:  0 BAD:  0\n",
      "1550 BCE:  0.015731846913695335 GOOD:  0 BAD:  0\n",
      "1600 BCE:  0.015996640548110008 GOOD:  0 BAD:  0\n",
      "1650 BCE:  0.015796320512890816 GOOD:  0 BAD:  0\n",
      "1700 BCE:  0.015842072665691376 GOOD:  0 BAD:  0\n",
      "1750 BCE:  0.01600371114909649 GOOD:  0 BAD:  0\n",
      "1800 BCE:  0.0158036220818758 GOOD:  0 BAD:  0\n",
      "1850 BCE:  0.015693500638008118 GOOD:  0 BAD:  0\n",
      "1900 BCE:  0.015872986987233162 GOOD:  0 BAD:  0\n",
      "1950 BCE:  0.015996824949979782 GOOD:  0 BAD:  0\n",
      "2000 BCE:  0.015802225098013878 GOOD:  0 BAD:  0\n",
      "2050 BCE:  0.015954606235027313 GOOD:  0 BAD:  0\n",
      "2100 BCE:  0.015916135162115097 GOOD:  0 BAD:  0\n",
      "2150 BCE:  0.016095371916890144 GOOD:  0 BAD:  0\n",
      "2200 BCE:  0.016098560765385628 GOOD:  0 BAD:  0\n",
      "2250 BCE:  0.01600368693470955 GOOD:  0 BAD:  0\n",
      "2300 BCE:  0.016203410923480988 GOOD:  0 BAD:  0\n",
      "2350 BCE:  0.0161195807158947 GOOD:  0 BAD:  0\n",
      "2400 BCE:  0.016587546095252037 GOOD:  0 BAD:  0\n",
      "2450 BCE:  0.016003593802452087 GOOD:  0 BAD:  0\n",
      "2500 BCE:  0.0160322654992342 GOOD:  0 BAD:  0\n",
      "2550 BCE:  0.016147244721651077 GOOD:  0 BAD:  0\n",
      "2600 BCE:  0.01606333628296852 GOOD:  0 BAD:  0\n",
      "2650 BCE:  0.016275016590952873 GOOD:  0 BAD:  0\n",
      "2700 BCE:  0.01651540957391262 GOOD:  0 BAD:  0\n",
      "2750 BCE:  0.016627050936222076 GOOD:  0 BAD:  0\n",
      "2800 BCE:  0.01638921909034252 GOOD:  0 BAD:  0\n",
      "2850 BCE:  0.016544492915272713 GOOD:  0 BAD:  0\n"
     ]
    }
   ],
   "source": [
    "for i in tnrange(iter_no):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    batch_idx = train_idx[i].long()\n",
    "    batch_E_neural = train_E_neural[batch_idx : batch_idx+batch_size]\n",
    "    batch_I_neural = train_I_neural[batch_idx : batch_idx+batch_size]\n",
    "    batch_Z = Z_train[batch_idx : batch_idx+batch_size]\n",
    "    batch_loss_weights = loss_weights_train[batch_idx : batch_idx+batch_size]\n",
    "        \n",
    "    Z_pred = model(batch_E_neural,\n",
    "                    batch_I_neural)\n",
    "        \n",
    "    \n",
    "        \n",
    "    bce_loss = torch.mean(bce_criterion(Z_pred, batch_Z) * batch_loss_weights)\n",
    "\n",
    "    loss = bce_loss\n",
    "    \n",
    "    \n",
    "            \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if i%50 == 0:\n",
    "        model.eval()\n",
    "        Z_pred = model(test_E_neural, test_I_neural)\n",
    "        bce_loss = torch.mean(bce_criterion(Z_pred, Z_test) * loss_weights_test)\n",
    "        \n",
    "        Z_pred_disc = torch.zeros_like(Z_pred)\n",
    "        Z_idx = torch.where(Z_pred > 0.5)[0]\n",
    "        Z_pred_disc[Z_idx] = 1\n",
    "        \n",
    "        good_no = 0\n",
    "        bad_no = 0\n",
    "        for x in torch.where(Z_pred_disc == 1)[0]:\n",
    "            close_count = 0\n",
    "            for y in torch.where(Z_test == 1)[0]:\n",
    "                if torch.abs(x-y) <= 15:\n",
    "                    close_count += 1\n",
    "            if close_count > 0:\n",
    "                good_no += 1\n",
    "            else:\n",
    "                bad_no += 1\n",
    "                \n",
    "                \n",
    "        \n",
    "        print(i, \"BCE: \", bce_loss.item(), \"GOOD: \", good_no, \"BAD: \", bad_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.sequential[0].weight[0,0,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 151])\n"
     ]
    }
   ],
   "source": [
    "print(model.sequential[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
