{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from models.sub_cos_glm import Sub_Cos_GLM\n",
    "#from models.sub_tcn import Sub_TCN\n",
    "#from models.gru import GRU\n",
    "#from models.tcn_multilayer import TCN_Multilayer\n",
    "#from models.lstm import LSTM\n",
    "#from models.tcn import TCN\n",
    "#from models.sub_cos_tcn import Sub_Cos_TCN\n",
    "#from models.cos_tcn import Cos_TCN\n",
    "#from models.gru_exp import GRU\n",
    "#from models.gru_stacked import GRU_Stacked\n",
    "#from models.dend_gru import Dend_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/scratch/yjk27/\"\n",
    "experiment = \"OOP\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "I_neural_file = \"Ispikes_neural.npz\"\n",
    "#V_file  = \"vdata_T10_Ne2000_gA0.6_tauA1_gN0.6_Ni200_gG0.1_gB0.06_NA0.75_NMDA0.75_Er0.5_Ir7.4_random_NR_rep1000_stimseed1.npy\"\n",
    "#V_file = \"vdata_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_noDendNa_Er0.5_Ir7.4_random_NR_rep1000_stimseed1_set1.npy\"\n",
    "V_file = \"vdata_T10_Ne2000_gA0.6_tauA1_NbgClust4_gN0.8_Ni200_gG0.1_gB0.1_Nafactor0_Er0.5_Ir7.4_random_NR_rep1000_stimseed1.npy\"\n",
    "#V_file = \"V_diff_NA1.5_NMDA0.75_stimseed1.npy\"\n",
    "#V_file = \"V_diff_stimseed1_set1.npy\"\n",
    "\n",
    "#E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "#I_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+I_neural_file)\n",
    "E_neural = scipy.sparse.load_npz(base_dir+\"CA1_clust4-60/data/\"+E_neural_file)\n",
    "I_neural = scipy.sparse.load_npz(base_dir+\"CA1_clust4-60/data/\"+I_neural_file)\n",
    "V = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+V_file)[:,:50000].flatten()\n",
    "#V = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+V_file)\n",
    "V = torch.from_numpy(V)\n",
    "V -= torch.mean(V)\n",
    "\n",
    "\"\"\"\n",
    "eloc_file = \"Elocs_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1_set1.npy\"\n",
    "iloc_file = \"Ilocs_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1_set1.npy\"\n",
    "eloc = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+eloc_file)\n",
    "iloc = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+iloc_file)\n",
    "\n",
    "den_idx = np.unique(eloc[880:1120,0])\n",
    "e_idx = np.where(np.isin(eloc[:,0], den_idx) == True)[0]\n",
    "i_idx = np.where(np.isin(iloc[:,0], den_idx) == True)[0]\n",
    "e_idx = torch.from_numpy(e_idx)\n",
    "i_idx = torch.from_numpy(i_idx)\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "#V_test_raw = np.load(\"/media/hdd01/sklee/\"+experiment+\"/data/V_diff_stimseed1.npy\")\n",
    "#V_test_raw = torch.from_numpy(V_test_raw)\n",
    "#V_test_raw -= torch.mean(V_test_raw)\n",
    "\n",
    "#test_E_neural_raw = scipy.sparse.load_npz(\"/media/hdd01/sklee/\"+experiment+\"/data/Espikes_neural.npz\")\n",
    "#test_I_neural_raw = scipy.sparse.load_npz(\"/media/hdd01/sklee/\"+experiment+\"/data/Ispikes_neural.npz\")\n",
    "#####\n",
    "\n",
    "C_syn_e = np.load(base_dir+\"CA1_clust4-60\"+\"/data/handsub1_C_syn_e.npy\")\n",
    "C_syn_i = np.load(base_dir+\"CA1_clust4-60\"+\"/data/handsub1_C_syn_i.npy\")\n",
    "C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "C_syn_i = torch.from_numpy(C_syn_i).float()\n",
    "\n",
    "#C_syn_e = C_syn_e[:,e_idx]\n",
    "#C_syn_i = C_syn_i[:,i_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = 980 * 1000 * 50\n",
    "T_test = 1 * 1000 * 50\n",
    "H_no = 1\n",
    "#sub_no = 1\n",
    "E_no = 2000\n",
    "I_no = 200\n",
    "#E_no = e_idx.shape[0]\n",
    "#I_no = i_idx.shape[0]\n",
    "T_no = 500\n",
    "#T_no = 350\n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "#layer_no = 3\n",
    "\n",
    "increment = 50\n",
    "batch_length = 50000\n",
    "batch_size = 5\n",
    "iter_no = 9800*2\n",
    "epoch_no = iter_no*batch_length*batch_size//T_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train = V[:T_train].float()\n",
    "V_test = V[-50000:].to(device).float()\n",
    "\n",
    "#V_test = V_test_raw[50000*993:50000*994].to(device).float()\n",
    "\n",
    "test_E_neural = E_neural[-50000:].toarray()\n",
    "test_I_neural = I_neural[-50000:].toarray()\n",
    "#test_E_neural = E_neural[50000*993:50000*994].toarray()\n",
    "#test_I_neural = I_neural[50000*993:50000*994].toarray()\n",
    "#test_E_neural = test_E_neural_raw[50000*993:50000*994].toarray()\n",
    "#test_I_neural = test_I_neural_raw[50000*993:50000*994].toarray()\n",
    "train_E_neural = E_neural[:T_train]\n",
    "train_I_neural = I_neural[:T_train]\n",
    "\n",
    "test_E_neural = torch.from_numpy(test_E_neural).float().to(device)\n",
    "test_I_neural = torch.from_numpy(test_I_neural).float().to(device)\n",
    "\n",
    "train_idx = np.empty((epoch_no, T_train//batch_length//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0, T_train, batch_length*batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263\n"
     ]
    }
   ],
   "source": [
    "model = Sub_Cos_GLM(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "#model = GRU(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "#model = GRU_Stacked(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "#model = Sub_TCN(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "#model = LSTM(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "#model = TCN(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, layer_no, device)\n",
    "#model = Sub_Cos_TCN(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, layer_no, device)\n",
    "#model = Cos_TCN(E_no, I_no, T_no, H_no, layer_no, device)\n",
    "#model = TCN_Multilayer(T_no-1, 2200, layer_no, H_no, device)\n",
    "#model = Dend_GRU(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "\n",
    "# GLM (1.025 for V_diff, 1 for noNA)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005/(1.035**100))\n",
    "milestones = np.arange(increment-1, increment*100, increment)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=1.035)\n",
    "\n",
    "# GRU (1 for V_diff, 1 for noNA)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = 0.005/(1**100))\n",
    "#milestones = np.arange(increment-1, increment*100, increment)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=1)\n",
    "\n",
    "#TCN multilayer\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = 0.0025,\n",
    "                             #weight_decay=0.0000001) # for TCNMUlti\n",
    "                             #weight_decay=0)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-3de3e3b01b3b>:3: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254fb56d02db4ecc840c9050c99dacb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.054036 -0.057677\n"
     ]
    }
   ],
   "source": [
    "score_list = np.empty((iter_no))\n",
    "\n",
    "for i in tnrange(iter_no):\n",
    "#for i in tnrange(12000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_idx = train_idx[i].long()\n",
    "    batch_E_neural = train_E_neural[batch_idx : batch_idx+batch_length*batch_size].toarray().reshape(batch_size, batch_length, -1)\n",
    "    batch_I_neural = train_I_neural[batch_idx : batch_idx+batch_length*batch_size].toarray().reshape(batch_size, batch_length, -1)\n",
    "    batch_E_neural = torch.from_numpy(batch_E_neural).float().to(device)\n",
    "    batch_I_neural = torch.from_numpy(batch_I_neural).float().to(device)\n",
    "    batch_V = V_train[batch_idx : batch_idx+batch_length*batch_size].reshape(batch_size, -1).to(device)\n",
    "    \n",
    "    V_pred, _, _ = model(batch_E_neural, batch_I_neural)\n",
    "    #V_pred, _ = model(batch_E_neural, batch_I_neural)\n",
    "    #V_pred, _ = model(batch_E_neural[:,5000:35000,e_idx], batch_I_neural[:,5000:35000,i_idx])\n",
    "    #V_pred = model(batch_E_neural, batch_I_neural)\n",
    "    \n",
    "    train_score = explained_variance_score(batch_V[:,:].flatten().cpu().detach().numpy(),\n",
    "                                           V_pred.flatten().cpu().detach().numpy())\n",
    "    \n",
    "    loss = torch.mean((V_pred- batch_V[:,:] )**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_V_pred, test_sub_out, _ = model(test_E_neural.unsqueeze(0), test_I_neural.unsqueeze(0))\n",
    "        #test_V_pred, _ = model(test_E_neural.unsqueeze(0), test_I_neural.unsqueeze(0))\n",
    "        #test_V_pred, test_sub_out = model(test_E_neural.unsqueeze(0)[:,5000:35000,e_idx], test_I_neural.unsqueeze(0)[:,5000:35000,i_idx])\n",
    "        #test_V_pred = model(test_E_neural.unsqueeze(0), test_I_neural.unsqueeze(0))\n",
    "        test_V_pred = test_V_pred.flatten()\n",
    "                 \n",
    "        test_score = explained_variance_score(V_test.cpu().detach().numpy()[:], test_V_pred.cpu().detach().numpy())\n",
    "        test_mse = torch.mean((V_test[:]-test_V_pred)**2).item()\n",
    "        score_list[i//50] = test_score\n",
    "                \n",
    "        print(i, np.round(test_score,6),\n",
    "              np.round(train_score,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(score_list[:350])\n",
    "#plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(V_test.cpu().detach().numpy()[17000:27000])\n",
    "plt.plot(test_V_pred.cpu().detach().numpy()[17000:27000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/scratch/yjk27/CA1_OOP/nona/glm_s1_h1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
