{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from models.sub_cos_glm import Sub_Cos_GLM\n",
    "#from models.sub_tcn import Sub_TCN\n",
    "from models.gru import GRU\n",
    "from models.gru_stacked import GRU_Stacked\n",
    "from models.sub_cos_glm_stacked import Sub_Cos_GLM_Stacked\n",
    "from models.gru_multilayer import GRU_Multilayer\n",
    "from models.sub_cos_glm_multilayer import Sub_Cos_GLM_Multilayer\n",
    "from models.tcn_multilayer import TCN_Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/scratch/yjk27/\"\n",
    "experiment = \"clust4-60\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "I_neural_file = \"Ispikes_neural.npz\"\n",
    "clust_mode = \"whole\"\n",
    "model_type = \"tcnmulti\"\n",
    "\n",
    "#E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "#I_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+I_neural_file)\n",
    "E_neural = scipy.sparse.load_npz(\"/scratch/yjk27/CA1_clust4-60/data/\"+E_neural_file)\n",
    "I_neural = scipy.sparse.load_npz(\"/scratch/yjk27/CA1_clust4-60/data/\"+I_neural_file)\n",
    "\n",
    "if (clust_mode == \"hand\") or (clust_mode == \"whole\") or (clust_mode == \"global\"):\n",
    "    C_syn_e = np.load(\"/scratch/yjk27/\"+cell_type+\"_\"+experiment+\"/data/handsub5_C_syn_e.npy\")\n",
    "    C_syn_i = np.load(\"/scratch/yjk27/\"+cell_type+\"_\"+experiment+\"/data/handsub5_C_syn_i.npy\")\n",
    "    C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "    C_syn_i = torch.from_numpy(C_syn_i).float()\n",
    "elif clust_mode == \"rand\":\n",
    "    C_syn_e = np.load(\"/scratch/yjk27/\"+cell_type+\"_\"+experiment+\"/data/randsub5_C_syn_e.npy\")\n",
    "    C_syn_i = np.load(\"/scratch/yjk27/\"+cell_type+\"_\"+experiment+\"/data/randsub5_C_syn_i.npy\")\n",
    "    C_syn_e = torch.from_numpy(C_syn_e).float()\n",
    "    C_syn_i = torch.from_numpy(C_syn_i).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_no = 40\n",
    "layer_no = 3\n",
    "sub_no = 5\n",
    "sub_no_file = 5\n",
    "E_no = 2000\n",
    "I_no = 200\n",
    "T_no = 350\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30715361\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"gru\":\n",
    "    model = GRU(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "elif model_type == \"grustack\":\n",
    "    model = GRU_Stacked(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "#elif model_type == \"tcn\":\n",
    "    #model = Sub_TCN(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"glm\":\n",
    "    model = Sub_Cos_GLM(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"glmstack\":\n",
    "    model = Sub_Cos_GLM_Stacked(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"grumulti\":\n",
    "    model = GRU_Multilayer(C_syn_e.to(device), C_syn_i.to(device), H_no, device)\n",
    "elif model_type == \"glmmulti\":\n",
    "    model = Sub_Cos_GLM_Multilayer(C_syn_e.to(device), C_syn_i.to(device), T_no, H_no, device)\n",
    "elif model_type == \"tcnmulti\":\n",
    "    model = TCN_Multilayer(T_no-1, E_no+I_no, layer_no, H_no, device)\n",
    "    \n",
    "model.to(device).float()\n",
    "model.load_state_dict(torch.load(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_l\"+str(layer_no)+\"_h\"+str(H_no)+\".pt\", map_location='cuda:0'))\n",
    "#model.load_state_dict(torch.load(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no_file)+\"_h\"+str(H_no)+\".pt\", map_location='cuda:0'))\n",
    "#model.load_state_dict(torch.load(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no_file)+\"_h\"+str(H_no)+\"_set5.pt\", map_location='cuda:0'))\n",
    "model.eval()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-896bcb47a41b>:42: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(20):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0996335dc4754230878f8b4fc53900b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (model_type == \"gru\") or (model_type == \"grustack\") or (model_type==\"grumulti\"):\n",
    "    test = np.zeros((20,50000))\n",
    "    sub_out = np.zeros((20, sub_no, 50000))\n",
    "\n",
    "    for i in tnrange(20):\n",
    "        if i < 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "        elif i == 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "\n",
    "        #############\n",
    "        ############\n",
    "        #part_I_neural = torch.zeros_like(part_I_neural)\n",
    "        ############\n",
    "        ############\n",
    "        \n",
    "        part_test, part_sub_out = model(part_E_neural, part_I_neural)\n",
    "        test[i] = part_test.cpu().detach().numpy().flatten()\n",
    "        sub_out[i] = part_sub_out.squeeze(0).T.cpu().detach().numpy()\n",
    "        \n",
    "    E_scale = np.exp(model.E_scale.cpu().detach().numpy())\n",
    "    np.savez(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no)+\"_h\"+str(H_no)+\"_output.npz\",\n",
    "        test=test,\n",
    "        sub_out=sub_out,\n",
    "        E_scale = E_scale)\n",
    "    \n",
    "    ############\n",
    "    ############\n",
    "    #np.savez(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no)+\"_h\"+str(H_no)+\"_pos_output.npz\",\n",
    "        #test=test,\n",
    "        #sub_out=sub_out,\n",
    "        #E_scale = E_scale)\n",
    "    ############\n",
    "    ############\n",
    "\n",
    "elif (model_type == \"tcnmulti\"):\n",
    "    test = np.zeros((20,50000))\n",
    "    sub_out = np.zeros((20, sub_no, 50000))\n",
    "\n",
    "    for i in tnrange(20):\n",
    "        if i < 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "        elif i == 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "        \n",
    "        part_test = model(part_E_neural, part_I_neural)\n",
    "        test[i] = part_test.cpu().detach().numpy().flatten()\n",
    "        \n",
    "    np.savez(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no)+\"_h\"+str(H_no)+\"_output.npz\",\n",
    "        test=test)\n",
    "    \n",
    "elif (model_type == \"glm\") or (model_type == \"glmstack\") or (model_type == \"glmmulti\"):\n",
    "    test = np.zeros((20,50000))\n",
    "    nonlin_in = np.zeros((20,sub_no,H_no, 50000))\n",
    "    sub_out = np.zeros((20, sub_no, 50000))\n",
    "    \n",
    "    for i in tnrange(20):\n",
    "        if i < 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:(-19+i)*50000].toarray()).to(device).float().unsqueeze(0)\n",
    "        elif i == 19:\n",
    "            part_E_neural = torch.from_numpy(E_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "            part_I_neural = torch.from_numpy(I_neural[(-20+i)*50000:].toarray()).to(device).float().unsqueeze(0)\n",
    "\n",
    "        part_test, part_sub_out, part_nonlin_in = model(part_E_neural, part_I_neural)\n",
    "        test[i] = part_test.cpu().detach().numpy().flatten()\n",
    "        #sub_out[i] = part_sub_out.squeeze(0).T.cpu().detach().numpy()\n",
    "        #nonlin_in[i] = part_nonlin_in.squeeze(0).reshape(sub_no, H_no, -1).cpu().detach().numpy()\n",
    "        \n",
    "    cos_basis_no = 30\n",
    "    scale = 7.5\n",
    "    shift = 1\n",
    "        \n",
    "    kern_basis = torch.zeros(cos_basis_no, T_no).to(device)\n",
    "    for i in range(cos_basis_no):\n",
    "        phi = 1.5707963267948966*i\n",
    "        xmin = phi - 3.141592653589793\n",
    "        xmax = phi + 3.141592653589793\n",
    "\n",
    "        x_in = torch.arange(0, T_no, 1)\n",
    "        raw_cos = scale  * torch.log(x_in + shift + 1e-7)\n",
    "\n",
    "        basis = 0.5*torch.cos(raw_cos - phi) + 0.5\n",
    "        basis[raw_cos < xmin] = 0.0\n",
    "        basis[raw_cos > xmax] = 0.0\n",
    "        kern_basis[i] = basis\n",
    "        \n",
    "    e_kern = torch.matmul(model.W_e_layer1, kern_basis).reshape(sub_no, H_no, T_no).cpu().detach().numpy()\n",
    "    i_kern = torch.matmul(model.W_i_layer1, kern_basis).reshape(sub_no, H_no, T_no).cpu().detach().numpy()\n",
    "    \n",
    "    E_scale = np.exp(model.E_scale.cpu().detach().numpy())\n",
    "    np.savez(base_dir+cell_type+\"_\"+experiment+\"/\"+clust_mode+\"/\"+model_type+\"_s\"+str(sub_no_file)+\"_h\"+str(H_no)+\"_output.npz\",\n",
    "        test=test,\n",
    "        nonlin_in=nonlin_in,\n",
    "        sub_out=sub_out,\n",
    "        e_kern=e_kern,\n",
    "        i_kern=i_kern,\n",
    "        E_scale=E_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
