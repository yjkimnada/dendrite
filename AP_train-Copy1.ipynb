{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a2844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268ec9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AP_NN(nn.Module):\n",
    "    def __init__(self, K_no, L_no, H_no, T_no, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.K_no = K_no\n",
    "        self.L_no = L_no\n",
    "        self.H_no = H_no\n",
    "        self.T_no = T_no\n",
    "        self.device = device\n",
    "        \n",
    "        nn_list = []\n",
    "        for l in range(self.L_no):\n",
    "            if l == 0:\n",
    "                nn_list.append(nn.Conv1d(in_channels=2, out_channels=H_no, kernel_size=K_no, padding=0))\n",
    "                #nn_list.append(nn.Tanh())\n",
    "                nn_list.append(nn.LeakyReLU())\n",
    "            elif l == self.L_no - 1:\n",
    "                nn_list.append(nn.Conv1d(in_channels=H_no, out_channels=1, kernel_size=1, padding=0))\n",
    "            else:\n",
    "                nn_list.append(nn.Conv1d(in_channels=H_no, out_channels=H_no, kernel_size=1, padding=0))\n",
    "                #nn_list.append(nn.Tanh())\n",
    "                nn_list.append(nn.LeakyReLU())\n",
    "        \n",
    "        self.nn = nn.Sequential(*nn_list)\n",
    "        \n",
    "        self.cos_basis_no = 30\n",
    "        self.scale = 7.5\n",
    "        self.shift = 1\n",
    "        self.kern_basis = torch.zeros(self.cos_basis_no, T_no).to(device)\n",
    "        for i in range(self.cos_basis_no):\n",
    "            phi = 1.5707963267948966*i\n",
    "            xmin = phi - 3.141592653589793\n",
    "            xmax = phi + 3.141592653589793\n",
    "\n",
    "            x_in = torch.arange(0, T_no, 1)\n",
    "            raw_cos = self.scale  * torch.log(x_in + self.shift + 1e-7)\n",
    "\n",
    "            basis = 0.5*torch.cos(raw_cos - phi) + 0.5\n",
    "            basis[raw_cos < xmin] = 0.0\n",
    "            basis[raw_cos > xmax] = 0.0\n",
    "            self.kern_basis[i] = basis\n",
    "        self.W_refract = nn.Parameter(torch.randn(self.cos_basis_no)*0.01)\n",
    "        \n",
    "    def train_forward(self, V, D, S):\n",
    "        #V, D, S is shape (batch, 50000)\n",
    "        \n",
    "        input_pad = torch.zeros(V.shape[0], 2, V.shape[1] + self.K_no-1).to(self.device)\n",
    "        input_pad[:,0,-V.shape[1]:] = input_pad[:,0,-V.shape[1]:] + V\n",
    "        input_pad[:,1,-D.shape[1]:] = input_pad[:,1,-D.shape[1]:] + D\n",
    "        \n",
    "        S_pad = torch.zeros(S.shape[0], 1, S.shape[1] + self.T_no-1).to(self.device)\n",
    "        S_pad[:, 0, -S.shape[1]:] = S_pad[:, 0, -S.shape[1]:] + S\n",
    "        refract_kern = torch.flip(torch.matmul(self.kern_basis.T, self.W_refract), [0]) #(T_no)\n",
    "        \n",
    "        nn_out = self.nn(input_pad).squeeze(1) # (batch, 50000)\n",
    "        S_conv = F.conv1d(S_pad, refract_kern.reshape(1,1,-1)).squeeze(1)\n",
    "        \n",
    "        P = torch.sigmoid(nn_out + S_conv)\n",
    "        return P\n",
    "    \n",
    "    def test_forward(self, V, D):\n",
    "        #V, D is shape (batch, 50000)\n",
    "        \n",
    "        input_pad = torch.zeros(V.shape[0], 2, V.shape[1] + self.K_no-1).to(self.device)\n",
    "        input_pad[:,0,-V.shape[1]:] = input_pad[:,0,-V.shape[1]:] + V\n",
    "        input_pad[:,1,-D.shape[1]:] = input_pad[:,1,-D.shape[1]:] + D\n",
    "        \n",
    "        refract_kern = torch.flip(torch.matmul(self.kern_basis.T, self.W_refract), [0]) #(T_no)\n",
    "        \n",
    "        nn_out = self.nn(input_pad).squeeze(1) # (batch, 50000)\n",
    "        \n",
    "        S_out_pad = torch.zeros(V.shape[0], V.shape[1] + self.T_no).to(self.device)\n",
    "        P_out = torch.zeros(V.shape[0], V.shape[1]).to(self.device)\n",
    "        \n",
    "        for t in range(V.shape[1]):\n",
    "            nn_t = nn_out[:,t].clone() #(batch)\n",
    "            refract_t = torch.sum(S_out_pad[:,t:t+self.T_no].clone() * refract_kern.reshape(1,-1) , 1) #(batch)\n",
    "            P_t = torch.sigmoid(nn_t + refract_t)\n",
    "            S_out_pad[:,self.T_no+t] = S_out_pad[:,self.T_no+t] + torch.bernoulli(P_t)\n",
    "            P_out[:,t] = P_out[:,t] + P_t\n",
    "        \n",
    "        S_out = S_out_pad[:,self.T_no:]\n",
    "        return S_out, P_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aecb8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "batch_length = 50000\n",
    "K_no = 1\n",
    "L_no = 2\n",
    "H_no = 20\n",
    "T_no = 501\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "epoch_no = 100\n",
    "iter_no = epoch_no * 980 // batch_size\n",
    "\n",
    "V = np.load(\"/media/hdd01/sklee/CA1_clust4-60_AP/comb_pred/V_comb_pred.npy\").flatten()\n",
    "D = np.zeros((V.shape[0]))\n",
    "D[:-1] = np.diff(V)\n",
    "#D = V.copy()\n",
    "D = D.reshape(-1,batch_length)\n",
    "V = V.reshape(-1,batch_length)\n",
    "S = np.load(\"/media/hdd01/sklee/CA1_clust4-60_AP/data/spk.npy\").reshape(-1,batch_length)\n",
    "\n",
    "V = torch.from_numpy(V)\n",
    "D = torch.from_numpy(D)\n",
    "S = torch.from_numpy(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d3c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train = V[:980].float()\n",
    "V_test = V[980:].float().to(device)\n",
    "D_train = D[:980].float()\n",
    "D_test = D[980:].float().to(device)\n",
    "S_train = S[:980].float()\n",
    "S_test = S[980:].float() .to(device)\n",
    "\n",
    "train_idx = np.empty((epoch_no, 980//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0,980,batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5a56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "model = AP_NN(K_no, L_no, H_no, T_no, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "bce_criterion = nn.BCELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1bf54c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0bb8ea78a585>:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2155a0980154924b332ca4216e06466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5660656690597534 11.540967464447021\n",
      "49 0.13995273411273956 11.697033882141113\n",
      "99 0.10508427768945694 12.055019617080688\n",
      "149 0.08772184699773788 11.92812204360962\n",
      "199 0.07586076110601425 11.965021133422852\n",
      "249 0.06757237017154694 12.187100172042847\n",
      "299 0.0608924999833107 12.522115468978882\n",
      "349 0.0554383285343647 12.119268894195557\n",
      "399 0.05039117857813835 12.087712049484253\n",
      "449 0.045996300876140594 12.026589155197144\n",
      "499 0.04244004189968109 11.988090991973877\n",
      "549 0.038563597947359085 12.131720066070557\n",
      "599 0.03561520203948021 12.369555711746216\n",
      "649 0.03207675367593765 11.980798721313477\n",
      "699 0.02967669442296028 12.331401824951172\n",
      "749 0.027076510712504387 11.893225908279419\n",
      "799 0.024720443412661552 12.082522869110107\n",
      "849 0.02253718674182892 11.914998769760132\n",
      "899 0.02062053233385086 12.754130601882935\n",
      "949 0.019056176766753197 12.614485502243042\n",
      "999 0.01745535433292389 12.054714918136597\n",
      "1049 0.01615961268544197 12.126040935516357\n",
      "1099 0.014880486764013767 12.304299354553223\n",
      "1149 0.013924595899879932 12.19038438796997\n",
      "1199 0.012909650802612305 12.251197338104248\n",
      "1249 0.012238708324730396 12.271782398223877\n",
      "1299 0.011482967995107174 12.115485906600952\n",
      "1349 0.01093248836696148 12.65653133392334\n",
      "1399 0.0103693138808012 11.868617296218872\n",
      "1449 0.009935930371284485 11.924794673919678\n",
      "1499 0.0095395278185606 12.101746559143066\n",
      "1549 0.00917758233845234 12.25286078453064\n",
      "1599 0.008866500109434128 11.989048957824707\n",
      "1649 0.008569486439228058 12.14595913887024\n",
      "1699 0.008308904245495796 12.025259971618652\n",
      "1749 0.008060706779360771 12.193445682525635\n",
      "1799 0.007866435684263706 12.371880531311035\n",
      "1849 0.0076642828062176704 12.138328790664673\n",
      "1899 0.007479350548237562 11.83747124671936\n",
      "1949 0.007337240967899561 12.044222593307495\n",
      "1999 0.00718767149373889 12.401843786239624\n",
      "2049 0.00701379356905818 11.920687675476074\n",
      "2099 0.006877037230879068 12.432585000991821\n",
      "2149 0.00674552982673049 11.99954867362976\n",
      "2199 0.006614923011511564 11.942078590393066\n",
      "2249 0.006481235381215811 12.30396556854248\n",
      "2299 0.006349889561533928 12.282175540924072\n",
      "2349 0.006223449483513832 12.342631101608276\n",
      "2399 0.006098184268921614 12.141433715820312\n",
      "2449 0.005990173202008009 12.014935493469238\n",
      "2499 0.005881858989596367 12.157668828964233\n",
      "2549 0.005777254700660706 12.087967157363892\n",
      "2599 0.005672988016158342 12.190716981887817\n",
      "2649 0.005564755294471979 12.535014152526855\n",
      "2699 0.005476799793541431 12.067129611968994\n",
      "2749 0.00538517814129591 11.88936734199524\n",
      "2799 0.005287529900670052 12.206890106201172\n",
      "2849 0.005196486599743366 11.887977123260498\n",
      "2899 0.005096815526485443 12.605284452438354\n",
      "2949 0.005004881415516138 12.453169584274292\n",
      "2999 0.004911572206765413 11.942671298980713\n",
      "3049 0.00482266815379262 12.112306833267212\n",
      "3099 0.004724557511508465 11.899466753005981\n",
      "3149 0.0046305423602461815 12.277112007141113\n",
      "3199 0.004537004977464676 12.217865467071533\n",
      "3249 0.004434529226273298 12.081509113311768\n",
      "3299 0.004330433439463377 12.464622259140015\n",
      "3349 0.004231934901326895 12.017661333084106\n",
      "3399 0.00415657926350832 11.877583265304565\n",
      "3449 0.004092616960406303 12.12696623802185\n",
      "3499 0.0040376693941652775 12.09852147102356\n",
      "3549 0.003984479699283838 11.907757759094238\n",
      "3599 0.003940778784453869 11.855076313018799\n",
      "3649 0.00388308591209352 11.942416667938232\n",
      "3699 0.0038430881686508656 12.229986429214478\n",
      "3749 0.0038007500115782022 12.657636165618896\n",
      "3799 0.0037655229680240154 12.554004907608032\n",
      "3849 0.0037270565517246723 11.883861541748047\n",
      "3899 0.003693840466439724 12.506189346313477\n",
      "3949 0.003660655114799738 11.877099990844727\n",
      "3999 0.0036337587516754866 11.852413892745972\n",
      "4049 0.003600466763600707 12.080699443817139\n",
      "4099 0.0035705091431736946 12.101219415664673\n",
      "4149 0.003546932013705373 12.17452597618103\n",
      "4199 0.003525056876242161 12.052979469299316\n",
      "4249 0.00350239803083241 11.908825159072876\n",
      "4299 0.003481118706986308 11.930999040603638\n",
      "4349 0.0034605124965310097 11.894354104995728\n",
      "4399 0.0034409898798912764 11.922859191894531\n",
      "4449 0.0034215115010738373 12.470231533050537\n",
      "4499 0.003405654104426503 12.16702675819397\n",
      "4549 0.0033908660989254713 11.940587043762207\n",
      "4599 0.003373184008523822 12.392702341079712\n",
      "4649 0.0033600060269236565 12.386165142059326\n",
      "4699 0.0033406498841941357 11.861177682876587\n",
      "4749 0.0033320817165076733 12.155511379241943\n",
      "4799 0.003323179204016924 12.12327527999878\n",
      "4849 0.003310456173494458 12.181588411331177\n",
      "4899 0.003298597875982523 12.412660837173462\n",
      "4949 0.0032898655626922846 11.869897365570068\n",
      "4999 0.003276956034824252 11.988738775253296\n",
      "5049 0.003265686798840761 12.061809062957764\n",
      "5099 0.0032558897510170937 12.004744052886963\n",
      "5149 0.003248447785153985 12.658132553100586\n",
      "5199 0.00323567190207541 11.92124056816101\n",
      "5249 0.003230761969462037 12.631195545196533\n",
      "5299 0.0032224413007497787 12.530961751937866\n",
      "5349 0.00321480305865407 11.938497304916382\n",
      "5399 0.003207545494660735 11.94620418548584\n",
      "5449 0.0031987193506211042 12.212992906570435\n",
      "5499 0.003189999843016267 12.75819706916809\n",
      "5549 0.0031870512757450342 11.919745206832886\n",
      "5599 0.0031786479521542788 12.41365122795105\n",
      "5649 0.0031727540772408247 11.942733764648438\n",
      "5699 0.0031655484344810247 11.938862085342407\n",
      "5749 0.0031637498177587986 12.080522775650024\n",
      "5799 0.0031616808846592903 11.891019821166992\n",
      "5849 0.003151959041133523 12.440709829330444\n",
      "5899 0.003145576687529683 12.232630014419556\n",
      "5949 0.0031431731767952442 12.033618688583374\n",
      "5999 0.003136912826448679 12.087532043457031\n",
      "6049 0.003132097888737917 11.87399411201477\n",
      "6099 0.0031294110231101513 11.892067432403564\n",
      "6149 0.003121342044323683 12.237895727157593\n",
      "6199 0.0031258324161171913 11.98550820350647\n",
      "6249 0.003118004184216261 11.979345083236694\n",
      "6299 0.0031128590926527977 12.173705101013184\n",
      "6349 0.0031104644294828176 11.83592176437378\n",
      "6399 0.003109127748757601 12.006133556365967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0bb8ea78a585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#batch_P = model.train_forward(batch_V, batch_D, batch_S)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "\n",
    "part_time_idx = torch.arange(12000,32000)\n",
    "\n",
    "for i in tnrange(iter_no):\n",
    "    s = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_idx_start = train_idx[i]\n",
    "    batch_idx = torch.arange(batch_idx_start, batch_idx_start+5).long()\n",
    "    batch_S = S_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    batch_V = V_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    batch_D = D_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    \n",
    "    S_out, batch_P = model.test_forward(batch_V, batch_D)\n",
    "    #batch_P = model.train_forward(batch_V, batch_D, batch_S)\n",
    "    loss = bce_criterion(batch_P, batch_S)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_time = time.time() - s\n",
    "    \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_S_out, P_test = model.test_forward(V_test[:,part_time_idx], D_test[:,part_time_idx])\n",
    "        test_loss = bce_criterion(P_test, S_test[:,part_time_idx]).item()\n",
    "        \n",
    "        score_list.append(test_loss)\n",
    "        print(i, test_loss, step_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ecc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3fab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AP True\n",
    "# 0.00019483866344671696 (V, D)\n",
    "# 0.0006420775316655636 (V only)\n",
    "\n",
    "# Na True\n",
    "# 0.0012602820061147213 (V, D)\n",
    "# 0.0018874892266467214 (V only)\n",
    "\n",
    "# No Na True\n",
    "# 0.0013189633609727025 (V, D)\n",
    "# 0.0018882722361013293 (V only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3493c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20350c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0352, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(P_test[0][10000:15000].cpu().detach().numpy()[:])\n",
    "plt.scatter(np.arange(5000), S_test[0][12000:32000][10000:15000].cpu().detach().numpy()-0.8, s=100, color=\"black\", marker=\"|\")\n",
    "plt.scatter(np.arange(5000), test_S_out[0][10000:15000].cpu().detach().numpy()*0.9-0.8, s=100, color=\"red\", marker=\"|\")\n",
    "print(torch.max(P_test))\n",
    "plt.ylim(0,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d89c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0736, -0.0659, -0.0514, -0.0819, -0.0686, -0.0580, -0.0571, -0.0713,\n",
      "        -0.0655, -0.0548, -0.0797, -0.0690, -0.0780, -0.0737, -0.0669, -0.0584,\n",
      "        -0.0791, -0.0658, -0.0851, -0.0567, -0.0777, -0.0607, -0.0820, -0.0544,\n",
      "        -0.0594, -0.0449, -0.0556, -0.0695, -0.0523, -0.0618], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.W_refract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef988b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
