{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switching(nn.Module):\n",
    "    def __init__(self, state_no, hid_no, C_syn, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.K_no = state_no\n",
    "        self.H_no = hid_no\n",
    "        self.device = device\n",
    "        self.C_syn = C_syn\n",
    "        self.in_no = C_syn.shape[1]\n",
    "        self.N_no = C_syn.shape[0]\n",
    "        \n",
    "        self.spike = nn.Parameter(torch.ones(self.in_no), requires_grad=True)\n",
    "        \n",
    "        self.W_sz = nn.Parameter(torch.randn(self.K_no, self.K_no, self.H_no)*0.1, requires_grad=True)\n",
    "        self.W_sx = nn.Parameter(torch.randn(self.K_no, self.K_no, self.N_no)*0.1, requires_grad=True)\n",
    "        self.b_s = nn.Parameter(torch.randn(self.K_no, self.K_no)*0.1, requires_grad=True)\n",
    "        \n",
    "        self.W_zz = nn.Parameter(torch.randn(self.K_no, self.H_no, self.H_no)*0.1, requires_grad=True)\n",
    "        self.W_zx = nn.Parameter(torch.randn(self.K_no, self.H_no, self.N_no)*0.1, requires_grad=True)\n",
    "        self.b_z = nn.Parameter(torch.randn(self.K_no, self.H_no)*0.1, requires_grad=True)\n",
    "        \n",
    "        self.W_yz = nn.Parameter(torch.randn(self.H_no)*0.1, requires_grad=True)\n",
    "        self.b_y = nn.Parameter(torch.randn(1)*0.1, requires_grad=True)\n",
    "        \n",
    "    def forward(self, X, S, temp, test):\n",
    "        \n",
    "        # X is (batch_size, T_data, E_no)\n",
    "        T_data = X.shape[1]\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        X_scaled = X * self.spike.reshape(1,1,-1)\n",
    "        X_sub = torch.matmul(X_scaled, self.C_syn.T) # (batch, T_data, N_no)\n",
    "        \n",
    "        Z_out = torch.zeros(batch_size, T_data+1, self.H_no).to(self.device)\n",
    "        S_out = torch.zeros(batch_size, T_data+1, self.K_no).to(self.device)\n",
    "        S_out[:,0,0] = 1\n",
    "        \n",
    "        S_true = torch.zeros(batch_size, T_data+1, self.K_no).to(self.device)\n",
    "        S_true[:,-T_data:,:] = S_true[:,-T_data:,:] + S\n",
    "        \n",
    "        for t in range(T_data):\n",
    "            #prev_S = S_out[:,t,:].clone() # (batch, K_no)\n",
    "            prev_S = S_true[:,t,:].clone() # (batch, K_no)\n",
    "            prev_Z = Z_out[:,t,:].clone() # (batch, H_no)\n",
    "            curr_X = X_sub[:,t,:] # (batch, N_no)\n",
    "            \n",
    "            ### Calculate state vector ###\n",
    "            \n",
    "            W_sz_part = torch.sum(prev_S.unsqueeze(2).unsqueeze(3) * self.W_sz, 1) # (batch, K_no, H_no)\n",
    "            W_sx_part = torch.sum(prev_S.unsqueeze(2).unsqueeze(3) * self.W_sx, 1) # (batch, K_no, N_no)\n",
    "            b_s_part = torch.sum(prev_S.unsqueeze(2) * self.b_s, 1) # (batch, K_no)\n",
    "            \n",
    "            S_in = torch.matmul(W_sz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                                + torch.matmul(W_sx_part, curr_X.unsqueeze(2)).squeeze(2) \\\n",
    "                                + b_s_part # (batch, K_no)\n",
    "            \n",
    "            if test == True:\n",
    "                curr_S = torch.zeros(batch_size, self.K_no).to(self.device)\n",
    "                for b in range(batch_size):\n",
    "                    max_idx = torch.argmax(S_in[b])\n",
    "                    curr_S[b,max_idx] = 1\n",
    "            elif test == False:\n",
    "                curr_S = F.softmax(S_in / temp, 1)\n",
    "                \n",
    "            S_out[:,t+1,:] = S_out[:,t+1,:] + curr_S # (batch, K_no)\n",
    "            \n",
    "            ####\n",
    "            true_curr_S = S_true[:,t+1,:]\n",
    "            ####\n",
    "            \n",
    "            ### Calculate hidden Z ###\n",
    "            \n",
    "            W_zz_part = torch.sum(true_curr_S.unsqueeze(2).unsqueeze(3) * self.W_zz, 1) # (batch, H_no, H_no)\n",
    "            W_zx_part = torch.sum(true_curr_S.unsqueeze(2).unsqueeze(3) * self.W_zx, 1) # (batch, H_no, N_no)\n",
    "            b_z_part = torch.sum(true_curr_S.unsqueeze(2) * self.b_z, 1) # (batch, H_no)\n",
    "            \n",
    "            Z_in = torch.matmul(W_zz_part, prev_Z.unsqueeze(2)).squeeze(2) \\\n",
    "                            + torch.matmul(W_zx_part, curr_X.unsqueeze(2)).squeeze(2) \\\n",
    "                            + b_z_part # (batch, H_no)\n",
    "            \n",
    "            #curr_Z = torch.tanh(Z_in) # (batch, H_no)\n",
    "            curr_Z = Z_in\n",
    "            \n",
    "            Z_out[:,t+1,:] = Z_out[:,t+1,:] + curr_Z\n",
    "            \n",
    "        Y_out = torch.sum(Z_out[:,1:,:] * self.W_yz.reshape(1,1,-1), 2) + self.b_y\n",
    "        \n",
    "        return Y_out, Z_out[:,1:,:], S_out[:,1:,:]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/hdd01/sklee/\"\n",
    "experiment = \"clust4-60\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "V_file = \"V_diff.npy\"\n",
    "eloc_file = \"Elocs_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1.npy\"\n",
    "\n",
    "E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "V = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+V_file)\n",
    "V = torch.from_numpy(V)\n",
    "eloc = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+eloc_file)\n",
    "\n",
    "den_idx = np.unique(eloc[880:1120,0])\n",
    "e_idx = np.where(np.isin(eloc[:,0], den_idx) == True)[0]\n",
    "e_idx = torch.from_numpy(e_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train = 999 * 1000 * 50\n",
    "T_test = 1 * 1000 * 50\n",
    "hid_no = 6 # H\n",
    "sub_no = 4 # N\n",
    "state_no = 8 # K\n",
    "in_no = 299\n",
    "save_dir = base_dir+cell_type+\"_\"+experiment+\"/\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_length = 50000\n",
    "batch_size = 9\n",
    "iter_no = 20000\n",
    "epoch_no = iter_no*batch_length*batch_size//T_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train = V[:T_train].float()\n",
    "V_test = V[T_train:T_train + T_test].to(device).float()\n",
    "\n",
    "test_E_neural = E_neural[T_train:T_train+T_test].toarray()\n",
    "train_E_neural = E_neural[:T_train]\n",
    "test_E_neural = torch.from_numpy(test_E_neural).float().to(device)\n",
    "\n",
    "train_idx = np.empty((epoch_no, T_train//batch_length//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0, T_train, batch_length*batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_syn = torch.zeros(sub_no, in_no).to(device)\n",
    "for i in range(in_no):\n",
    "    idx = e_idx[i]\n",
    "    if eloc[idx,0] == den_idx[0]:\n",
    "        C_syn[0,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[1]:\n",
    "        C_syn[1,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[2]:\n",
    "        C_syn[2,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[3]:\n",
    "        C_syn[3,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538\n"
     ]
    }
   ],
   "source": [
    "model = Switching(state_no, hid_no, C_syn, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0025)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.75)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "bce_criterion = nn.BCELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-6570fcb1865f>:9: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4352c76abd124560be260aa2ef7bb31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.70297479629517\n",
      "0 -0.009752 0.037773\n",
      "91.74267053604126\n"
     ]
    }
   ],
   "source": [
    "temp_list = np.logspace(-0.5, -3, 50)\n",
    "temp_count = 0\n",
    "\n",
    "S_true = torch.zeros(batch_size, batch_length, state_no).to(device)\n",
    "for m in range(batch_size):\n",
    "    idx = np.random.randint(0,state_no, batch_length)\n",
    "    S_true[m,np.arange(batch_length),idx] = 1\n",
    "\n",
    "for i in tnrange(iter_no):\n",
    "    s = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (i%50 == 49) & (temp_count < 49):\n",
    "        temp_count += 1\n",
    "    temp = temp_list[temp_count] \n",
    "    \n",
    "    batch_idx = train_idx[i].long()\n",
    "    batch_E_neural = train_E_neural[batch_idx : batch_idx+batch_length*batch_size].toarray().reshape(batch_size, batch_length, -1)\n",
    "    batch_E_neural = torch.from_numpy(batch_E_neural).float().to(device)\n",
    "    batch_V = V_train[batch_idx : batch_idx+batch_length*batch_size].reshape(batch_size, -1).to(device)\n",
    "    \n",
    "    V_pred, Z_out, S_out = model(batch_E_neural[:,:,e_idx], S_true, temp, False)\n",
    "                    \n",
    "    loss = torch.mean((V_pred - batch_V)**2) + bce_criterion(S_out.reshape(-1,state_no), S_true.reshape(-1,state_no))   \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    print(time.time() - s)\n",
    "        \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_V_pred, test_Z_out, test_S_out = model(test_E_neural[:,e_idx].unsqueeze(0), S_true[0].unsqueeze(0), 0, True)        \n",
    "        test_V_pred = test_V_pred.flatten()\n",
    "                 \n",
    "        test_score = explained_variance_score(V_test.cpu().detach().numpy(), test_V_pred.cpu().detach().numpy())\n",
    "        test_mse = torch.mean((V_test-test_V_pred)**2).item()\n",
    "        \n",
    "        print(i, np.round(test_score,6),\n",
    "              np.round(test_mse,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
