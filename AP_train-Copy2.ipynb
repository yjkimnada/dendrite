{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a2844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268ec9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AP_NN(nn.Module):\n",
    "    def __init__(self, K_no, L_no, H_no, T_no, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.K_no = K_no\n",
    "        self.L_no = L_no\n",
    "        self.H_no = H_no\n",
    "        self.T_no = T_no\n",
    "        self.device = device\n",
    "        \n",
    "        nn_list = []\n",
    "        for l in range(self.L_no):\n",
    "            if l == 0:\n",
    "                nn_list.append(nn.Conv1d(in_channels=2, out_channels=H_no, kernel_size=K_no, padding=0))\n",
    "                #nn_list.append(nn.Tanh())\n",
    "                nn_list.append(nn.LeakyReLU())\n",
    "            elif l == self.L_no - 1:\n",
    "                nn_list.append(nn.Conv1d(in_channels=H_no, out_channels=1, kernel_size=1, padding=0))\n",
    "            else:\n",
    "                nn_list.append(nn.Conv1d(in_channels=H_no, out_channels=H_no, kernel_size=1, padding=0))\n",
    "                #nn_list.append(nn.Tanh())\n",
    "                nn_list.append(nn.LeakyReLU())\n",
    "        \n",
    "        self.nn = nn.Sequential(*nn_list)\n",
    "        \n",
    "        self.cos_basis_no = 30\n",
    "        self.scale = 7.5\n",
    "        self.shift = 1\n",
    "        self.kern_basis = torch.zeros(self.cos_basis_no, T_no).to(device)\n",
    "        for i in range(self.cos_basis_no):\n",
    "            phi = 1.5707963267948966*i\n",
    "            xmin = phi - 3.141592653589793\n",
    "            xmax = phi + 3.141592653589793\n",
    "\n",
    "            x_in = torch.arange(0, T_no, 1)\n",
    "            raw_cos = self.scale  * torch.log(x_in + self.shift + 1e-7)\n",
    "\n",
    "            basis = 0.5*torch.cos(raw_cos - phi) + 0.5\n",
    "            basis[raw_cos < xmin] = 0.0\n",
    "            basis[raw_cos > xmax] = 0.0\n",
    "            self.kern_basis[i] = basis\n",
    "        self.W_refract = nn.Parameter(torch.randn(self.cos_basis_no)*0.01)\n",
    "        \n",
    "    def train_forward(self, V, D, S):\n",
    "        #V, D, S is shape (batch, 50000)\n",
    "        \n",
    "        input_pad = torch.zeros(V.shape[0], 2, V.shape[1] + self.K_no-1).to(self.device)\n",
    "        input_pad[:,0,-V.shape[1]:] = input_pad[:,0,-V.shape[1]:] + V\n",
    "        input_pad[:,1,-D.shape[1]:] = input_pad[:,1,-D.shape[1]:] + D\n",
    "        \n",
    "        S_pad = torch.zeros(S.shape[0], 1, S.shape[1] + self.T_no-1).to(self.device)\n",
    "        S_pad[:, 0, -S.shape[1]:] = S_pad[:, 0, -S.shape[1]:] + S\n",
    "        refract_kern = torch.flip(torch.matmul(self.kern_basis.T, self.W_refract), [0]) #(T_no)\n",
    "        \n",
    "        nn_out = self.nn(input_pad).squeeze(1) # (batch, 50000)\n",
    "        S_conv = F.conv1d(S_pad, refract_kern.reshape(1,1,-1)).squeeze(1)\n",
    "        \n",
    "        P = torch.sigmoid(nn_out + S_conv)\n",
    "        return P\n",
    "    \n",
    "    def test_forward(self, V, D):\n",
    "        #V, D is shape (batch, 50000)\n",
    "        \n",
    "        input_pad = torch.zeros(V.shape[0], 2, V.shape[1] + self.K_no-1).to(self.device)\n",
    "        input_pad[:,0,-V.shape[1]:] = input_pad[:,0,-V.shape[1]:] + V\n",
    "        input_pad[:,1,-D.shape[1]:] = input_pad[:,1,-D.shape[1]:] + D\n",
    "        \n",
    "        refract_kern = torch.flip(torch.matmul(self.kern_basis.T, self.W_refract), [0]) #(T_no)\n",
    "        \n",
    "        nn_out = self.nn(input_pad).squeeze(1) # (batch, 50000)\n",
    "        \n",
    "        S_out_pad = torch.zeros(V.shape[0], V.shape[1] + self.T_no).to(self.device)\n",
    "        P_out = torch.zeros(V.shape[0], V.shape[1]).to(self.device)\n",
    "        \n",
    "        for t in range(V.shape[1]):\n",
    "            nn_t = nn_out[:,t].clone() #(batch)\n",
    "            refract_t = torch.sum(S_out_pad[:,t:t+self.T_no].clone() * refract_kern.reshape(1,-1) , 1) #(batch)\n",
    "            P_t = torch.sigmoid(nn_t + refract_t)\n",
    "            S_out_pad[:,self.T_no+t] = S_out_pad[:,self.T_no+t] + torch.bernoulli(P_t)\n",
    "            P_out[:,t] = P_out[:,t] + P_t\n",
    "        \n",
    "        S_out = S_out_pad[:,self.T_no:]\n",
    "        return S_out, P_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aecb8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "batch_length = 50000\n",
    "K_no = 1\n",
    "L_no = 2\n",
    "H_no = 20\n",
    "T_no = 501\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "epoch_no = 100\n",
    "iter_no = epoch_no * 980 // batch_size\n",
    "\n",
    "V = np.load(\"/media/hdd01/sklee/CA1_clust4-60_AP/whole_pred/V_whole_pred.npy\").flatten()\n",
    "D = np.zeros((V.shape[0]))\n",
    "D[:-1] = np.diff(V)\n",
    "#D = V.copy()\n",
    "D = D.reshape(-1,batch_length)\n",
    "V = V.reshape(-1,batch_length)\n",
    "S = np.load(\"/media/hdd01/sklee/CA1_clust4-60_AP/data/spk.npy\").reshape(-1,batch_length)\n",
    "\n",
    "V = torch.from_numpy(V)\n",
    "D = torch.from_numpy(D)\n",
    "S = torch.from_numpy(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d3c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train = V[:980].float()\n",
    "V_test = V[980:].float().to(device)\n",
    "D_train = D[:980].float()\n",
    "D_test = D[980:].float().to(device)\n",
    "S_train = S[:980].float()\n",
    "S_test = S[980:].float() .to(device)\n",
    "\n",
    "train_idx = np.empty((epoch_no, 980//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0,980,batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5a56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "model = AP_NN(K_no, L_no, H_no, T_no, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "bce_criterion = nn.BCELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1bf54c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0bb8ea78a585>:5: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1713796c2f3f4d5aa9952c9c4bab01e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.968844175338745 11.741902589797974\n",
      "49 0.21069130301475525 11.514561653137207\n",
      "99 0.16463318467140198 11.76706576347351\n",
      "149 0.137567400932312 11.907082557678223\n",
      "199 0.11972232908010483 12.154505252838135\n",
      "249 0.10623878985643387 12.329416513442993\n",
      "299 0.09443661570549011 12.177319765090942\n",
      "349 0.0858876183629036 11.957801818847656\n",
      "399 0.07800249010324478 11.863227128982544\n",
      "449 0.07069950550794601 12.12735366821289\n",
      "499 0.06472206860780716 11.905217409133911\n",
      "549 0.05897210165858269 12.401768207550049\n",
      "599 0.05407917872071266 12.187415361404419\n",
      "649 0.04972364008426666 11.80048394203186\n",
      "699 0.04509451240301132 12.326048612594604\n",
      "749 0.04129864275455475 12.013504266738892\n",
      "799 0.03764045983552933 11.997360229492188\n",
      "849 0.03409597650170326 11.948017358779907\n",
      "899 0.031031060963869095 11.856309652328491\n",
      "949 0.028222840279340744 12.210047245025635\n",
      "999 0.025762371718883514 11.95114517211914\n",
      "1049 0.023335633799433708 12.074995279312134\n",
      "1099 0.021422432735562325 11.878858804702759\n",
      "1149 0.019556572660803795 12.527464389801025\n",
      "1199 0.018070245161652565 12.258232831954956\n",
      "1249 0.016609404236078262 11.949347257614136\n",
      "1299 0.015343600884079933 11.86657452583313\n",
      "1349 0.014311857521533966 11.814685583114624\n",
      "1399 0.01336351502686739 12.020677328109741\n",
      "1449 0.012554404325783253 11.977306127548218\n",
      "1499 0.011868848465383053 11.857081890106201\n",
      "1549 0.011250427924096584 11.987866163253784\n",
      "1599 0.01071672048419714 11.8475821018219\n",
      "1649 0.01026034913957119 12.281213283538818\n",
      "1699 0.009830904193222523 11.898790121078491\n",
      "1749 0.009505178779363632 11.933194160461426\n",
      "1799 0.009148095734417439 12.482431888580322\n",
      "1849 0.008880851790308952 11.972693681716919\n",
      "1899 0.008627330884337425 11.768552780151367\n",
      "1949 0.008393088355660439 12.051281213760376\n",
      "1999 0.008184929378330708 11.812294006347656\n",
      "2049 0.007994193583726883 12.007814884185791\n",
      "2099 0.007821616716682911 12.04864239692688\n",
      "2149 0.007652222644537687 12.31161379814148\n",
      "2199 0.007498184684664011 11.810481309890747\n",
      "2249 0.007357823196798563 12.447917461395264\n",
      "2299 0.007236692123115063 12.05904221534729\n",
      "2349 0.0071117570623755455 12.447352886199951\n",
      "2399 0.00698848906904459 12.383267164230347\n",
      "2449 0.006881105247884989 11.955142974853516\n",
      "2499 0.006773135159164667 11.760319709777832\n",
      "2549 0.006673232186585665 12.115750551223755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 0.006137683056294918 11.932565212249756\n",
      "2899 0.006054421421140432 12.22451400756836\n",
      "2949 0.005973384249955416 12.086410522460938\n",
      "2999 0.005895501002669334 11.81776762008667\n",
      "3049 0.005819998681545258 12.241919755935669\n",
      "3099 0.005743364337831736 11.79019808769226\n",
      "3149 0.005666273180395365 11.824287414550781\n",
      "3199 0.005590352229773998 11.823102474212646\n",
      "3249 0.0055124289356172085 12.407118082046509\n",
      "3299 0.005444358568638563 11.868498086929321\n",
      "3349 0.005370005965232849 12.30112624168396\n",
      "3399 0.005292859859764576 12.456624269485474\n",
      "3449 0.005219427868723869 11.779123067855835\n",
      "3499 0.005146080628037453 11.99294662475586\n",
      "3549 0.005073107313364744 12.35074496269226\n",
      "3599 0.004999170545488596 11.800252437591553\n",
      "3649 0.004928955342620611 11.922362804412842\n",
      "3699 0.004857879597693682 12.335243701934814\n",
      "3749 0.004782919771969318 11.919750452041626\n",
      "3799 0.0047121369279921055 12.547306060791016\n",
      "3849 0.0046373819932341576 11.795273065567017\n",
      "3899 0.004562561400234699 12.224626302719116\n",
      "3949 0.0044896299950778484 11.763567924499512\n",
      "3999 0.0044141593389213085 11.925227880477905\n",
      "4049 0.004343194421380758 11.770340919494629\n",
      "4099 0.00427437387406826 12.137523412704468\n",
      "4149 0.004208202473819256 11.774460077285767\n",
      "4199 0.004147871397435665 12.190325260162354\n",
      "4249 0.004095630720257759 12.109226703643799\n",
      "4299 0.0040501696057617664 11.759306907653809\n",
      "4349 0.0040039727464318275 12.28303575515747\n",
      "4399 0.003955809865146875 12.650309801101685\n",
      "4449 0.003918609581887722 11.790053844451904\n",
      "4499 0.003879264462739229 11.884427309036255\n",
      "4549 0.003842204576358199 11.779166221618652\n",
      "4599 0.003808014327660203 12.114749670028687\n",
      "4649 0.0037749733310192823 11.90760064125061\n",
      "4699 0.003739969339221716 12.510443687438965\n",
      "4749 0.003714011749252677 11.8037588596344\n",
      "4799 0.0036841691471636295 11.920112371444702\n",
      "4849 0.0036572173703461885 12.324885368347168\n",
      "4899 0.0036337480414658785 11.861622333526611\n",
      "4949 0.003611119696870446 11.826176166534424\n",
      "4999 0.0035876482725143433 11.885207891464233\n",
      "5049 0.003566898638382554 12.220577478408813\n",
      "5099 0.0035450791474431753 11.818512201309204\n",
      "5149 0.003527618246152997 11.871147155761719\n",
      "5199 0.0035095205530524254 12.12010908126831\n",
      "5249 0.00349184381775558 11.978410959243774\n",
      "5299 0.0034743724390864372 12.164467096328735\n",
      "5349 0.003458478022366762 12.03208065032959\n",
      "5399 0.0034458383452147245 11.856262683868408\n",
      "5449 0.003429644275456667 11.861412525177002\n",
      "5499 0.0034163810778409243 11.968682765960693\n",
      "5549 0.0034037120640277863 11.863491773605347\n",
      "5599 0.003388797864317894 11.739929676055908\n",
      "5649 0.0033768753055483103 11.803833484649658\n",
      "5699 0.003366112941876054 11.809753894805908\n",
      "5749 0.0033545971382409334 11.803881406784058\n",
      "5799 0.0033445078879594803 12.580016851425171\n",
      "5849 0.003334478475153446 11.906521797180176\n",
      "5899 0.003324291668832302 12.241028070449829\n",
      "5949 0.0033169155940413475 12.420437574386597\n",
      "5999 0.0033046691678464413 12.401513814926147\n",
      "6049 0.003298073308542371 11.820130348205566\n",
      "6099 0.0032888322602957487 12.523262739181519\n",
      "6149 0.0032815553713589907 12.183145761489868\n",
      "6199 0.00327345822006464 11.801763534545898\n",
      "6249 0.003265846986323595 11.917942762374878\n",
      "6299 0.003260282101109624 12.097737789154053\n",
      "6349 0.0032517604995518923 12.012789964675903\n",
      "6399 0.0032463259994983673 12.358229160308838\n",
      "6449 0.0032399583142250776 12.085166931152344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0bb8ea78a585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#batch_P = model.train_forward(batch_V, batch_D, batch_S)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "\n",
    "part_time_idx = torch.arange(12000,32000)\n",
    "\n",
    "for i in tnrange(iter_no):\n",
    "    s = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_idx_start = train_idx[i]\n",
    "    batch_idx = torch.arange(batch_idx_start, batch_idx_start+5).long()\n",
    "    batch_S = S_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    batch_V = V_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    batch_D = D_train[batch_idx].to(device)[:,part_time_idx]\n",
    "    \n",
    "    S_out, batch_P = model.test_forward(batch_V, batch_D)\n",
    "    #batch_P = model.train_forward(batch_V, batch_D, batch_S)\n",
    "    loss = bce_criterion(batch_P, batch_S)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_time = time.time() - s\n",
    "    \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_S_out, P_test = model.test_forward(V_test[:,part_time_idx], D_test[:,part_time_idx])\n",
    "        test_loss = bce_criterion(P_test, S_test[:,part_time_idx]).item()\n",
    "        \n",
    "        score_list.append(test_loss)\n",
    "        print(i, test_loss, step_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763d251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AP True\n",
    "# 0.00019483866344671696 (V, D)\n",
    "# 0.0006420775316655636 (V only)\n",
    "\n",
    "# Na True\n",
    "# 0.0012602820061147213 (V, D)\n",
    "# 0.0018874892266467214 (V only)\n",
    "\n",
    "# No Na True\n",
    "# 0.0013189633609727025 (V, D)\n",
    "# 0.0018882722361013293 (V only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3493c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20350c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0228, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(P_test[0][10000:15000].cpu().detach().numpy()[:])\n",
    "plt.scatter(np.arange(5000), S_test[0][12000:32000][10000:15000].cpu().detach().numpy()-0.8, s=100, color=\"black\", marker=\"|\")\n",
    "plt.scatter(np.arange(5000), test_S_out[0][10000:15000].cpu().detach().numpy()*0.9-0.8, s=100, color=\"red\", marker=\"|\")\n",
    "print(torch.max(P_test))\n",
    "plt.ylim(0,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89c01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
