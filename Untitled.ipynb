{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tnrange\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGLM(nn.Module):\n",
    "    def __init__(self, C_syn, T_no, sub_no, in_no, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.T_no = T_no\n",
    "        self.in_no = in_no\n",
    "        self.device = device\n",
    "        self.C_syn = C_syn\n",
    "        self.sub_no = sub_no\n",
    "        \n",
    "        self.spike = nn.Parameter(torch.ones(self.in_no), requires_grad=True)\n",
    "        self.kern = nn.Parameter(torch.ones(self.sub_no, self.T_no)*0.01, requires_grad=True)\n",
    "        self.hist = nn.Parameter(torch.ones(self.sub_no, self.T_no)*0.01, requires_grad=True)\n",
    "        self.theta = nn.Parameter(torch.ones(self.sub_no)*0, requires_grad=True)\n",
    "        self.scale = nn.Parameter(torch.ones(self.sub_no)*1, requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.ones(1)*0, requires_grad=True)\n",
    "        \n",
    "    def forward(self, S):\n",
    "        T_data = S.shape[0]\n",
    "        \n",
    "        S = S * self.spike.reshape(1,-1)\n",
    "        S = torch.matmul(S, self.C_syn.T)\n",
    "        S_pad = torch.zeros(T_data + self.T_no-1, self.sub_no).to(self.device)\n",
    "        S_pad[-T_data:] = S_pad[-T_data:] + S\n",
    "        \n",
    "        kern = torch.flip(self.kern, [1]).unsqueeze(1)\n",
    "        S_conv = F.conv1d(S_pad.T.unsqueeze(0), kern, groups=self.sub_no).squeeze(0).T\n",
    "        \n",
    "        sub_out = torch.zeros(T_data + self.T_no, self.sub_no).to(self.device)\n",
    "        \n",
    "        for t in range(T_data):\n",
    "            out_hist = sub_out[t:t+self.T_no].clone()\n",
    "            hist_in = torch.sum(out_hist.T * torch.flip(self.hist, [1]) ,1)\n",
    "            t_out = torch.tanh(S_conv[t] + hist_in + self.theta)\n",
    "            sub_out[t+self.T_no] = sub_out[t+self.T_no] + t_out\n",
    "            \n",
    "        final = torch.matmul(sub_out[self.T_no:], self.scale).flatten() + self.bias\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/hdd01/sklee/\"\n",
    "experiment = \"clust4-60\"\n",
    "cell_type = \"CA1\"\n",
    "E_neural_file = \"Espikes_neural.npz\"\n",
    "eloc_file = \"Elocs_T10_Ne2000_gA0.6_tauA1_gN0.8_Ni200_gG0.1_gB0.1_Er0.5_Ir7.4_random_NR_rep1000_stimseed1.npy\"\n",
    "device = \"cuda\"\n",
    "\n",
    "E_neural = scipy.sparse.load_npz(base_dir+cell_type+\"_\"+experiment+\"/data/\"+E_neural_file)\n",
    "eloc = np.load(base_dir+cell_type+\"_\"+experiment+\"/data/\"+eloc_file)\n",
    "\n",
    "den_idx = np.unique(eloc[880:1120,0])\n",
    "e_idx = np.where(np.isin(eloc[:,0], den_idx) == True)[0]\n",
    "e_idx = torch.from_numpy(e_idx)\n",
    "\n",
    "#V = np.load(\"/media/hdd01/sklee/CA1_clust4-60/gru_s4_h4_nospat_subout.npy\")\n",
    "V = np.load(\"/media/hdd01/sklee/CA1_clust4-60/data/V_diff.npy\")\n",
    "\n",
    "V = torch.from_numpy(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_no = 299\n",
    "T_no = 500\n",
    "sub_no = 4\n",
    "device = torch.device(\"cuda\")\n",
    "#sub = 1\n",
    "batch_size = 5000\n",
    "\n",
    "epoch_no = 50\n",
    "\n",
    "C_syn = torch.zeros(sub_no, in_no).to(device)\n",
    "for i in range(in_no):\n",
    "    idx = e_idx[i]\n",
    "    if eloc[idx,0] == den_idx[0]:\n",
    "        C_syn[0,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[1]:\n",
    "        C_syn[1,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[2]:\n",
    "        C_syn[2,i] = 1\n",
    "    elif eloc[idx,0] == den_idx[3]:\n",
    "        C_syn[3,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_test = V[199*50000:200*50000].float()\n",
    "V_train = V[:199*50000].to(device).float()\n",
    "\n",
    "test_E_neural = E_neural[199*50000:200*50000].toarray()\n",
    "train_E_neural = E_neural[:199*50000]\n",
    "test_E_neural = torch.from_numpy(test_E_neural).float().to(device)\n",
    "\n",
    "iter_no = epoch_no*199*50000//batch_size\n",
    "train_idx = np.empty((epoch_no, 199*50000//batch_size))\n",
    "for i in range(epoch_no):\n",
    "    part_idx = np.arange(0,199*50000,batch_size)\n",
    "    np.random.shuffle(part_idx)\n",
    "    train_idx[i] = part_idx\n",
    "train_idx = train_idx.flatten()\n",
    "train_idx = torch.from_numpy(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4308\n"
     ]
    }
   ],
   "source": [
    "model = TestGLM(C_syn, T_no, sub_no, in_no, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0025)\n",
    "\n",
    "model.to(device).float()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-7ed9e0a9b246>:1: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(iter_no):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6b68cc53184e8bab88d10f624be1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9950.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 0 -3.905197 -6.617205\n",
      "TEST 49 -0.309106 -0.353519\n",
      "TEST 99 -0.195627 -0.168668\n"
     ]
    }
   ],
   "source": [
    "for i in tnrange(iter_no):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    batch_idx = train_idx[i].long()\n",
    "    batch_E_neural = train_E_neural[batch_idx:batch_idx+batch_size].toarray()\n",
    "    batch_E_neural = torch.from_numpy(batch_E_neural).float().to(device)\n",
    "    batch_V = V_train[batch_idx:batch_idx+batch_size].to(device)\n",
    "    \n",
    "    V_pred = model(batch_E_neural[:,e_idx])\n",
    "    \n",
    "    train_score = explained_variance_score(batch_V.cpu().detach().numpy(), V_pred.cpu().detach().numpy())\n",
    "            \n",
    "    loss = torch.var(V_pred - batch_V)\n",
    "    #loss = torch.mean((V_pred - batch_V)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #train_score = explained_variance_score(batch_V.cpu().detach().numpy(), V_pred.cpu().detach().numpy())\n",
    "    #print(np.round(train_score,6))\n",
    "    \n",
    "    if (i%50 == 49) or (i == 0):\n",
    "        model.eval()\n",
    "        test_V_pred = model(test_E_neural[:,e_idx])\n",
    "        test_score = explained_variance_score(V_test.cpu().detach().numpy(), test_V_pred.cpu().detach().numpy())\n",
    "        \n",
    "        print(\"TEST\", i, np.round(test_score,6),\n",
    "              np.round(train_score,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_E_neural.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f142859f190>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "#plt.plot(V_test.cpu().detach().numpy()[16000:26000])\n",
    "plt.plot(test_V_pred.cpu().detach().numpy()[16000:26000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
